{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e828d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Qwen-Image-Edit-Angles\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/Qwen-Image-Edit-Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f531872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping import of cpp extensions due to incompatible torch version 2.9.1+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info\n",
      "TMA benchmarks will be running without grid constant TMA descriptor.\n",
      "WARNING:bitsandbytes.cextension:Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "ERROR:bitsandbytes.cextension:Could not load bitsandbytes native library: /lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.32' not found (required by /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cpu.so)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py\", line 85, in <module>\n",
      "    lib = get_native_library()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py\", line 72, in get_native_library\n",
      "    dll = ct.cdll.LoadLibrary(str(binary_path))\n",
      "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 452, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: /lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.32' not found (required by /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cpu.so)\n",
      "WARNING:bitsandbytes.cextension:\n",
      "CUDA Setup failed despite CUDA being available. Please run the following command to get more information:\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n",
      "to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n",
      "and open an issue at: https://github.com/bitsandbytes-foundation/bitsandbytes/issues\n",
      "\n",
      "2025-11-23 07:32:06.358872: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-23 07:32:06.373313: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763883126.391228 2355409 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763883126.396766 2355409 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1763883126.409466 2355409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763883126.409483 2355409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763883126.409485 2355409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763883126.409487 2355409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-23 07:32:06.413587: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.12) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/utils/fixes.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version  # type: ignore\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6bfafbeb9f4769a0e5e143fe7a4d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from qwenimage.reporting.datamodels import ExperimentSet\n",
    "from qwenimage.reporting.visualize_barplot import compare_sets_with_timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/ubuntu/.local/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>lpips_mean</th>\n",
       "      <th>lpips_std</th>\n",
       "      <th>time_mean</th>\n",
       "      <th>time_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qwen_base</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098381</td>\n",
       "      <td>0.036231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qwen_te_int8wo</td>\n",
       "      <td>0.188574</td>\n",
       "      <td>0.095865</td>\n",
       "      <td>0.132210</td>\n",
       "      <td>0.029275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwen_te_fp8row</td>\n",
       "      <td>0.212102</td>\n",
       "      <td>0.113812</td>\n",
       "      <td>0.169402</td>\n",
       "      <td>0.026132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen_te_int4wo_qkv</td>\n",
       "      <td>0.231104</td>\n",
       "      <td>0.111931</td>\n",
       "      <td>0.129037</td>\n",
       "      <td>0.028168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qwen_te_int4wo_linear</td>\n",
       "      <td>0.229536</td>\n",
       "      <td>0.107802</td>\n",
       "      <td>0.122848</td>\n",
       "      <td>0.027134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qwen_te_int4wo_linear_nofirstlast</td>\n",
       "      <td>0.227104</td>\n",
       "      <td>0.119267</td>\n",
       "      <td>0.127067</td>\n",
       "      <td>0.030136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          experiment  lpips_mean  lpips_std  time_mean  \\\n",
       "0                          qwen_base    0.000000   0.000000   0.098381   \n",
       "1                     qwen_te_int8wo    0.188574   0.095865   0.132210   \n",
       "2                     qwen_te_fp8row    0.212102   0.113812   0.169402   \n",
       "3                 qwen_te_int4wo_qkv    0.231104   0.111931   0.129037   \n",
       "4              qwen_te_int4wo_linear    0.229536   0.107802   0.122848   \n",
       "5  qwen_te_int4wo_linear_nofirstlast    0.227104   0.119267   0.127067   \n",
       "\n",
       "   time_std  \n",
       "0  0.036231  \n",
       "1  0.029275  \n",
       "2  0.026132  \n",
       "3  0.028168  \n",
       "4  0.027134  \n",
       "5  0.030136  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_sets_with_timing(\n",
    "    ExperimentSet.create(\n",
    "        \"qwen_base\",\n",
    "        \"qwen_te_int8wo\",\n",
    "        # \"qwen_te_int4wo\",\n",
    "        \"qwen_te_fp8row\",\n",
    "        \"qwen_te_int4wo_qkv\",\n",
    "        \"qwen_te_int4wo_linear\",\n",
    "        \"qwen_te_int4wo_linear_nofirstlast\",\n",
    "    ),\n",
    "    profile_target=\"Encode Prompt\",\n",
    "    sort_by=None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e730071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "import yaml\n",
    "import diffusers\n",
    "\n",
    "\n",
    "from wandml.trainers.experiment_trainer import ExperimentTrainer\n",
    "from wandml import WandDataPipe\n",
    "import wandml\n",
    "from wandml import WandAuth\n",
    "from wandml import utils as wandml_utils\n",
    "from wandml.trainers.datamodels import ExperimentTrainerParameters\n",
    "from wandml.trainers.experiment_trainer import ExperimentTrainer\n",
    "\n",
    "\n",
    "from qwenimage.finetuner import QwenLoraFinetuner\n",
    "from qwenimage.datasets import StyleSourceWithRandomRef\n",
    "from qwenimage.task import TextToImageWithRefTask\n",
    "from qwenimage.datamodels import QwenConfig\n",
    "from qwenimage.foundation import QwenImageFoundation\n",
    "from qwenimage.experiments.experiments_qwen import PipeInputs\n",
    "from qwenimage.models.encode_prompt import encode_prompt\n",
    "from qwenimage.optimization import simple_quantize_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2548215a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.device='cpu'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7f2dad19974600a61edcd39ab73d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da8c2cc72c24c86a2909a544f084980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041e06fcccb34c549ba3d0be97d4e5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af633e352504cc385338e754917a844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 input combinations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = QwenConfig()\n",
    "foundation = QwenImageFoundation(config=config, device=\"cpu\")\n",
    "text_encoder = foundation.text_encoder.to(\"cuda\")\n",
    "\n",
    "inps = PipeInputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e09b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['model.visual.patch_embed.proj.weight', 'model.visual.blocks.0.norm1.weight', 'model.visual.blocks.0.norm2.weight', 'model.visual.blocks.0.attn.qkv.weight', 'model.visual.blocks.0.attn.qkv.bias', 'model.visual.blocks.0.attn.proj.weight', 'model.visual.blocks.0.attn.proj.bias', 'model.visual.blocks.0.mlp.gate_proj.weight', 'model.visual.blocks.0.mlp.gate_proj.bias', 'model.visual.blocks.0.mlp.up_proj.weight', 'model.visual.blocks.0.mlp.up_proj.bias', 'model.visual.blocks.0.mlp.down_proj.weight', 'model.visual.blocks.0.mlp.down_proj.bias', 'model.visual.blocks.1.norm1.weight', 'model.visual.blocks.1.norm2.weight', 'model.visual.blocks.1.attn.qkv.weight', 'model.visual.blocks.1.attn.qkv.bias', 'model.visual.blocks.1.attn.proj.weight', 'model.visual.blocks.1.attn.proj.bias', 'model.visual.blocks.1.mlp.gate_proj.weight', 'model.visual.blocks.1.mlp.gate_proj.bias', 'model.visual.blocks.1.mlp.up_proj.weight', 'model.visual.blocks.1.mlp.up_proj.bias', 'model.visual.blocks.1.mlp.down_proj.weight', 'model.visual.blocks.1.mlp.down_proj.bias', 'model.visual.blocks.2.norm1.weight', 'model.visual.blocks.2.norm2.weight', 'model.visual.blocks.2.attn.qkv.weight', 'model.visual.blocks.2.attn.qkv.bias', 'model.visual.blocks.2.attn.proj.weight', 'model.visual.blocks.2.attn.proj.bias', 'model.visual.blocks.2.mlp.gate_proj.weight', 'model.visual.blocks.2.mlp.gate_proj.bias', 'model.visual.blocks.2.mlp.up_proj.weight', 'model.visual.blocks.2.mlp.up_proj.bias', 'model.visual.blocks.2.mlp.down_proj.weight', 'model.visual.blocks.2.mlp.down_proj.bias', 'model.visual.blocks.3.norm1.weight', 'model.visual.blocks.3.norm2.weight', 'model.visual.blocks.3.attn.qkv.weight', 'model.visual.blocks.3.attn.qkv.bias', 'model.visual.blocks.3.attn.proj.weight', 'model.visual.blocks.3.attn.proj.bias', 'model.visual.blocks.3.mlp.gate_proj.weight', 'model.visual.blocks.3.mlp.gate_proj.bias', 'model.visual.blocks.3.mlp.up_proj.weight', 'model.visual.blocks.3.mlp.up_proj.bias', 'model.visual.blocks.3.mlp.down_proj.weight', 'model.visual.blocks.3.mlp.down_proj.bias', 'model.visual.blocks.4.norm1.weight', 'model.visual.blocks.4.norm2.weight', 'model.visual.blocks.4.attn.qkv.weight', 'model.visual.blocks.4.attn.qkv.bias', 'model.visual.blocks.4.attn.proj.weight', 'model.visual.blocks.4.attn.proj.bias', 'model.visual.blocks.4.mlp.gate_proj.weight', 'model.visual.blocks.4.mlp.gate_proj.bias', 'model.visual.blocks.4.mlp.up_proj.weight', 'model.visual.blocks.4.mlp.up_proj.bias', 'model.visual.blocks.4.mlp.down_proj.weight', 'model.visual.blocks.4.mlp.down_proj.bias', 'model.visual.blocks.5.norm1.weight', 'model.visual.blocks.5.norm2.weight', 'model.visual.blocks.5.attn.qkv.weight', 'model.visual.blocks.5.attn.qkv.bias', 'model.visual.blocks.5.attn.proj.weight', 'model.visual.blocks.5.attn.proj.bias', 'model.visual.blocks.5.mlp.gate_proj.weight', 'model.visual.blocks.5.mlp.gate_proj.bias', 'model.visual.blocks.5.mlp.up_proj.weight', 'model.visual.blocks.5.mlp.up_proj.bias', 'model.visual.blocks.5.mlp.down_proj.weight', 'model.visual.blocks.5.mlp.down_proj.bias', 'model.visual.blocks.6.norm1.weight', 'model.visual.blocks.6.norm2.weight', 'model.visual.blocks.6.attn.qkv.weight', 'model.visual.blocks.6.attn.qkv.bias', 'model.visual.blocks.6.attn.proj.weight', 'model.visual.blocks.6.attn.proj.bias', 'model.visual.blocks.6.mlp.gate_proj.weight', 'model.visual.blocks.6.mlp.gate_proj.bias', 'model.visual.blocks.6.mlp.up_proj.weight', 'model.visual.blocks.6.mlp.up_proj.bias', 'model.visual.blocks.6.mlp.down_proj.weight', 'model.visual.blocks.6.mlp.down_proj.bias', 'model.visual.blocks.7.norm1.weight', 'model.visual.blocks.7.norm2.weight', 'model.visual.blocks.7.attn.qkv.weight', 'model.visual.blocks.7.attn.qkv.bias', 'model.visual.blocks.7.attn.proj.weight', 'model.visual.blocks.7.attn.proj.bias', 'model.visual.blocks.7.mlp.gate_proj.weight', 'model.visual.blocks.7.mlp.gate_proj.bias', 'model.visual.blocks.7.mlp.up_proj.weight', 'model.visual.blocks.7.mlp.up_proj.bias', 'model.visual.blocks.7.mlp.down_proj.weight', 'model.visual.blocks.7.mlp.down_proj.bias', 'model.visual.blocks.8.norm1.weight', 'model.visual.blocks.8.norm2.weight', 'model.visual.blocks.8.attn.qkv.weight', 'model.visual.blocks.8.attn.qkv.bias', 'model.visual.blocks.8.attn.proj.weight', 'model.visual.blocks.8.attn.proj.bias', 'model.visual.blocks.8.mlp.gate_proj.weight', 'model.visual.blocks.8.mlp.gate_proj.bias', 'model.visual.blocks.8.mlp.up_proj.weight', 'model.visual.blocks.8.mlp.up_proj.bias', 'model.visual.blocks.8.mlp.down_proj.weight', 'model.visual.blocks.8.mlp.down_proj.bias', 'model.visual.blocks.9.norm1.weight', 'model.visual.blocks.9.norm2.weight', 'model.visual.blocks.9.attn.qkv.weight', 'model.visual.blocks.9.attn.qkv.bias', 'model.visual.blocks.9.attn.proj.weight', 'model.visual.blocks.9.attn.proj.bias', 'model.visual.blocks.9.mlp.gate_proj.weight', 'model.visual.blocks.9.mlp.gate_proj.bias', 'model.visual.blocks.9.mlp.up_proj.weight', 'model.visual.blocks.9.mlp.up_proj.bias', 'model.visual.blocks.9.mlp.down_proj.weight', 'model.visual.blocks.9.mlp.down_proj.bias', 'model.visual.blocks.10.norm1.weight', 'model.visual.blocks.10.norm2.weight', 'model.visual.blocks.10.attn.qkv.weight', 'model.visual.blocks.10.attn.qkv.bias', 'model.visual.blocks.10.attn.proj.weight', 'model.visual.blocks.10.attn.proj.bias', 'model.visual.blocks.10.mlp.gate_proj.weight', 'model.visual.blocks.10.mlp.gate_proj.bias', 'model.visual.blocks.10.mlp.up_proj.weight', 'model.visual.blocks.10.mlp.up_proj.bias', 'model.visual.blocks.10.mlp.down_proj.weight', 'model.visual.blocks.10.mlp.down_proj.bias', 'model.visual.blocks.11.norm1.weight', 'model.visual.blocks.11.norm2.weight', 'model.visual.blocks.11.attn.qkv.weight', 'model.visual.blocks.11.attn.qkv.bias', 'model.visual.blocks.11.attn.proj.weight', 'model.visual.blocks.11.attn.proj.bias', 'model.visual.blocks.11.mlp.gate_proj.weight', 'model.visual.blocks.11.mlp.gate_proj.bias', 'model.visual.blocks.11.mlp.up_proj.weight', 'model.visual.blocks.11.mlp.up_proj.bias', 'model.visual.blocks.11.mlp.down_proj.weight', 'model.visual.blocks.11.mlp.down_proj.bias', 'model.visual.blocks.12.norm1.weight', 'model.visual.blocks.12.norm2.weight', 'model.visual.blocks.12.attn.qkv.weight', 'model.visual.blocks.12.attn.qkv.bias', 'model.visual.blocks.12.attn.proj.weight', 'model.visual.blocks.12.attn.proj.bias', 'model.visual.blocks.12.mlp.gate_proj.weight', 'model.visual.blocks.12.mlp.gate_proj.bias', 'model.visual.blocks.12.mlp.up_proj.weight', 'model.visual.blocks.12.mlp.up_proj.bias', 'model.visual.blocks.12.mlp.down_proj.weight', 'model.visual.blocks.12.mlp.down_proj.bias', 'model.visual.blocks.13.norm1.weight', 'model.visual.blocks.13.norm2.weight', 'model.visual.blocks.13.attn.qkv.weight', 'model.visual.blocks.13.attn.qkv.bias', 'model.visual.blocks.13.attn.proj.weight', 'model.visual.blocks.13.attn.proj.bias', 'model.visual.blocks.13.mlp.gate_proj.weight', 'model.visual.blocks.13.mlp.gate_proj.bias', 'model.visual.blocks.13.mlp.up_proj.weight', 'model.visual.blocks.13.mlp.up_proj.bias', 'model.visual.blocks.13.mlp.down_proj.weight', 'model.visual.blocks.13.mlp.down_proj.bias', 'model.visual.blocks.14.norm1.weight', 'model.visual.blocks.14.norm2.weight', 'model.visual.blocks.14.attn.qkv.weight', 'model.visual.blocks.14.attn.qkv.bias', 'model.visual.blocks.14.attn.proj.weight', 'model.visual.blocks.14.attn.proj.bias', 'model.visual.blocks.14.mlp.gate_proj.weight', 'model.visual.blocks.14.mlp.gate_proj.bias', 'model.visual.blocks.14.mlp.up_proj.weight', 'model.visual.blocks.14.mlp.up_proj.bias', 'model.visual.blocks.14.mlp.down_proj.weight', 'model.visual.blocks.14.mlp.down_proj.bias', 'model.visual.blocks.15.norm1.weight', 'model.visual.blocks.15.norm2.weight', 'model.visual.blocks.15.attn.qkv.weight', 'model.visual.blocks.15.attn.qkv.bias', 'model.visual.blocks.15.attn.proj.weight', 'model.visual.blocks.15.attn.proj.bias', 'model.visual.blocks.15.mlp.gate_proj.weight', 'model.visual.blocks.15.mlp.gate_proj.bias', 'model.visual.blocks.15.mlp.up_proj.weight', 'model.visual.blocks.15.mlp.up_proj.bias', 'model.visual.blocks.15.mlp.down_proj.weight', 'model.visual.blocks.15.mlp.down_proj.bias', 'model.visual.blocks.16.norm1.weight', 'model.visual.blocks.16.norm2.weight', 'model.visual.blocks.16.attn.qkv.weight', 'model.visual.blocks.16.attn.qkv.bias', 'model.visual.blocks.16.attn.proj.weight', 'model.visual.blocks.16.attn.proj.bias', 'model.visual.blocks.16.mlp.gate_proj.weight', 'model.visual.blocks.16.mlp.gate_proj.bias', 'model.visual.blocks.16.mlp.up_proj.weight', 'model.visual.blocks.16.mlp.up_proj.bias', 'model.visual.blocks.16.mlp.down_proj.weight', 'model.visual.blocks.16.mlp.down_proj.bias', 'model.visual.blocks.17.norm1.weight', 'model.visual.blocks.17.norm2.weight', 'model.visual.blocks.17.attn.qkv.weight', 'model.visual.blocks.17.attn.qkv.bias', 'model.visual.blocks.17.attn.proj.weight', 'model.visual.blocks.17.attn.proj.bias', 'model.visual.blocks.17.mlp.gate_proj.weight', 'model.visual.blocks.17.mlp.gate_proj.bias', 'model.visual.blocks.17.mlp.up_proj.weight', 'model.visual.blocks.17.mlp.up_proj.bias', 'model.visual.blocks.17.mlp.down_proj.weight', 'model.visual.blocks.17.mlp.down_proj.bias', 'model.visual.blocks.18.norm1.weight', 'model.visual.blocks.18.norm2.weight', 'model.visual.blocks.18.attn.qkv.weight', 'model.visual.blocks.18.attn.qkv.bias', 'model.visual.blocks.18.attn.proj.weight', 'model.visual.blocks.18.attn.proj.bias', 'model.visual.blocks.18.mlp.gate_proj.weight', 'model.visual.blocks.18.mlp.gate_proj.bias', 'model.visual.blocks.18.mlp.up_proj.weight', 'model.visual.blocks.18.mlp.up_proj.bias', 'model.visual.blocks.18.mlp.down_proj.weight', 'model.visual.blocks.18.mlp.down_proj.bias', 'model.visual.blocks.19.norm1.weight', 'model.visual.blocks.19.norm2.weight', 'model.visual.blocks.19.attn.qkv.weight', 'model.visual.blocks.19.attn.qkv.bias', 'model.visual.blocks.19.attn.proj.weight', 'model.visual.blocks.19.attn.proj.bias', 'model.visual.blocks.19.mlp.gate_proj.weight', 'model.visual.blocks.19.mlp.gate_proj.bias', 'model.visual.blocks.19.mlp.up_proj.weight', 'model.visual.blocks.19.mlp.up_proj.bias', 'model.visual.blocks.19.mlp.down_proj.weight', 'model.visual.blocks.19.mlp.down_proj.bias', 'model.visual.blocks.20.norm1.weight', 'model.visual.blocks.20.norm2.weight', 'model.visual.blocks.20.attn.qkv.weight', 'model.visual.blocks.20.attn.qkv.bias', 'model.visual.blocks.20.attn.proj.weight', 'model.visual.blocks.20.attn.proj.bias', 'model.visual.blocks.20.mlp.gate_proj.weight', 'model.visual.blocks.20.mlp.gate_proj.bias', 'model.visual.blocks.20.mlp.up_proj.weight', 'model.visual.blocks.20.mlp.up_proj.bias', 'model.visual.blocks.20.mlp.down_proj.weight', 'model.visual.blocks.20.mlp.down_proj.bias', 'model.visual.blocks.21.norm1.weight', 'model.visual.blocks.21.norm2.weight', 'model.visual.blocks.21.attn.qkv.weight', 'model.visual.blocks.21.attn.qkv.bias', 'model.visual.blocks.21.attn.proj.weight', 'model.visual.blocks.21.attn.proj.bias', 'model.visual.blocks.21.mlp.gate_proj.weight', 'model.visual.blocks.21.mlp.gate_proj.bias', 'model.visual.blocks.21.mlp.up_proj.weight', 'model.visual.blocks.21.mlp.up_proj.bias', 'model.visual.blocks.21.mlp.down_proj.weight', 'model.visual.blocks.21.mlp.down_proj.bias', 'model.visual.blocks.22.norm1.weight', 'model.visual.blocks.22.norm2.weight', 'model.visual.blocks.22.attn.qkv.weight', 'model.visual.blocks.22.attn.qkv.bias', 'model.visual.blocks.22.attn.proj.weight', 'model.visual.blocks.22.attn.proj.bias', 'model.visual.blocks.22.mlp.gate_proj.weight', 'model.visual.blocks.22.mlp.gate_proj.bias', 'model.visual.blocks.22.mlp.up_proj.weight', 'model.visual.blocks.22.mlp.up_proj.bias', 'model.visual.blocks.22.mlp.down_proj.weight', 'model.visual.blocks.22.mlp.down_proj.bias', 'model.visual.blocks.23.norm1.weight', 'model.visual.blocks.23.norm2.weight', 'model.visual.blocks.23.attn.qkv.weight', 'model.visual.blocks.23.attn.qkv.bias', 'model.visual.blocks.23.attn.proj.weight', 'model.visual.blocks.23.attn.proj.bias', 'model.visual.blocks.23.mlp.gate_proj.weight', 'model.visual.blocks.23.mlp.gate_proj.bias', 'model.visual.blocks.23.mlp.up_proj.weight', 'model.visual.blocks.23.mlp.up_proj.bias', 'model.visual.blocks.23.mlp.down_proj.weight', 'model.visual.blocks.23.mlp.down_proj.bias', 'model.visual.blocks.24.norm1.weight', 'model.visual.blocks.24.norm2.weight', 'model.visual.blocks.24.attn.qkv.weight', 'model.visual.blocks.24.attn.qkv.bias', 'model.visual.blocks.24.attn.proj.weight', 'model.visual.blocks.24.attn.proj.bias', 'model.visual.blocks.24.mlp.gate_proj.weight', 'model.visual.blocks.24.mlp.gate_proj.bias', 'model.visual.blocks.24.mlp.up_proj.weight', 'model.visual.blocks.24.mlp.up_proj.bias', 'model.visual.blocks.24.mlp.down_proj.weight', 'model.visual.blocks.24.mlp.down_proj.bias', 'model.visual.blocks.25.norm1.weight', 'model.visual.blocks.25.norm2.weight', 'model.visual.blocks.25.attn.qkv.weight', 'model.visual.blocks.25.attn.qkv.bias', 'model.visual.blocks.25.attn.proj.weight', 'model.visual.blocks.25.attn.proj.bias', 'model.visual.blocks.25.mlp.gate_proj.weight', 'model.visual.blocks.25.mlp.gate_proj.bias', 'model.visual.blocks.25.mlp.up_proj.weight', 'model.visual.blocks.25.mlp.up_proj.bias', 'model.visual.blocks.25.mlp.down_proj.weight', 'model.visual.blocks.25.mlp.down_proj.bias', 'model.visual.blocks.26.norm1.weight', 'model.visual.blocks.26.norm2.weight', 'model.visual.blocks.26.attn.qkv.weight', 'model.visual.blocks.26.attn.qkv.bias', 'model.visual.blocks.26.attn.proj.weight', 'model.visual.blocks.26.attn.proj.bias', 'model.visual.blocks.26.mlp.gate_proj.weight', 'model.visual.blocks.26.mlp.gate_proj.bias', 'model.visual.blocks.26.mlp.up_proj.weight', 'model.visual.blocks.26.mlp.up_proj.bias', 'model.visual.blocks.26.mlp.down_proj.weight', 'model.visual.blocks.26.mlp.down_proj.bias', 'model.visual.blocks.27.norm1.weight', 'model.visual.blocks.27.norm2.weight', 'model.visual.blocks.27.attn.qkv.weight', 'model.visual.blocks.27.attn.qkv.bias', 'model.visual.blocks.27.attn.proj.weight', 'model.visual.blocks.27.attn.proj.bias', 'model.visual.blocks.27.mlp.gate_proj.weight', 'model.visual.blocks.27.mlp.gate_proj.bias', 'model.visual.blocks.27.mlp.up_proj.weight', 'model.visual.blocks.27.mlp.up_proj.bias', 'model.visual.blocks.27.mlp.down_proj.weight', 'model.visual.blocks.27.mlp.down_proj.bias', 'model.visual.blocks.28.norm1.weight', 'model.visual.blocks.28.norm2.weight', 'model.visual.blocks.28.attn.qkv.weight', 'model.visual.blocks.28.attn.qkv.bias', 'model.visual.blocks.28.attn.proj.weight', 'model.visual.blocks.28.attn.proj.bias', 'model.visual.blocks.28.mlp.gate_proj.weight', 'model.visual.blocks.28.mlp.gate_proj.bias', 'model.visual.blocks.28.mlp.up_proj.weight', 'model.visual.blocks.28.mlp.up_proj.bias', 'model.visual.blocks.28.mlp.down_proj.weight', 'model.visual.blocks.28.mlp.down_proj.bias', 'model.visual.blocks.29.norm1.weight', 'model.visual.blocks.29.norm2.weight', 'model.visual.blocks.29.attn.qkv.weight', 'model.visual.blocks.29.attn.qkv.bias', 'model.visual.blocks.29.attn.proj.weight', 'model.visual.blocks.29.attn.proj.bias', 'model.visual.blocks.29.mlp.gate_proj.weight', 'model.visual.blocks.29.mlp.gate_proj.bias', 'model.visual.blocks.29.mlp.up_proj.weight', 'model.visual.blocks.29.mlp.up_proj.bias', 'model.visual.blocks.29.mlp.down_proj.weight', 'model.visual.blocks.29.mlp.down_proj.bias', 'model.visual.blocks.30.norm1.weight', 'model.visual.blocks.30.norm2.weight', 'model.visual.blocks.30.attn.qkv.weight', 'model.visual.blocks.30.attn.qkv.bias', 'model.visual.blocks.30.attn.proj.weight', 'model.visual.blocks.30.attn.proj.bias', 'model.visual.blocks.30.mlp.gate_proj.weight', 'model.visual.blocks.30.mlp.gate_proj.bias', 'model.visual.blocks.30.mlp.up_proj.weight', 'model.visual.blocks.30.mlp.up_proj.bias', 'model.visual.blocks.30.mlp.down_proj.weight', 'model.visual.blocks.30.mlp.down_proj.bias', 'model.visual.blocks.31.norm1.weight', 'model.visual.blocks.31.norm2.weight', 'model.visual.blocks.31.attn.qkv.weight', 'model.visual.blocks.31.attn.qkv.bias', 'model.visual.blocks.31.attn.proj.weight', 'model.visual.blocks.31.attn.proj.bias', 'model.visual.blocks.31.mlp.gate_proj.weight', 'model.visual.blocks.31.mlp.gate_proj.bias', 'model.visual.blocks.31.mlp.up_proj.weight', 'model.visual.blocks.31.mlp.up_proj.bias', 'model.visual.blocks.31.mlp.down_proj.weight', 'model.visual.blocks.31.mlp.down_proj.bias', 'model.visual.merger.ln_q.weight', 'model.visual.merger.mlp.0.weight', 'model.visual.merger.mlp.0.bias', 'model.visual.merger.mlp.2.weight', 'model.visual.merger.mlp.2.bias', 'model.language_model.embed_tokens.weight', 'model.language_model.layers.0.self_attn.q_proj.weight', 'model.language_model.layers.0.self_attn.q_proj.bias', 'model.language_model.layers.0.self_attn.k_proj.weight', 'model.language_model.layers.0.self_attn.k_proj.bias', 'model.language_model.layers.0.self_attn.v_proj.weight', 'model.language_model.layers.0.self_attn.v_proj.bias', 'model.language_model.layers.0.self_attn.o_proj.weight', 'model.language_model.layers.0.mlp.gate_proj.weight', 'model.language_model.layers.0.mlp.up_proj.weight', 'model.language_model.layers.0.mlp.down_proj.weight', 'model.language_model.layers.0.input_layernorm.weight', 'model.language_model.layers.0.post_attention_layernorm.weight', 'model.language_model.layers.1.self_attn.q_proj.weight', 'model.language_model.layers.1.self_attn.q_proj.bias', 'model.language_model.layers.1.self_attn.k_proj.weight', 'model.language_model.layers.1.self_attn.k_proj.bias', 'model.language_model.layers.1.self_attn.v_proj.weight', 'model.language_model.layers.1.self_attn.v_proj.bias', 'model.language_model.layers.1.self_attn.o_proj.weight', 'model.language_model.layers.1.mlp.gate_proj.weight', 'model.language_model.layers.1.mlp.up_proj.weight', 'model.language_model.layers.1.mlp.down_proj.weight', 'model.language_model.layers.1.input_layernorm.weight', 'model.language_model.layers.1.post_attention_layernorm.weight', 'model.language_model.layers.2.self_attn.q_proj.weight', 'model.language_model.layers.2.self_attn.q_proj.bias', 'model.language_model.layers.2.self_attn.k_proj.weight', 'model.language_model.layers.2.self_attn.k_proj.bias', 'model.language_model.layers.2.self_attn.v_proj.weight', 'model.language_model.layers.2.self_attn.v_proj.bias', 'model.language_model.layers.2.self_attn.o_proj.weight', 'model.language_model.layers.2.mlp.gate_proj.weight', 'model.language_model.layers.2.mlp.up_proj.weight', 'model.language_model.layers.2.mlp.down_proj.weight', 'model.language_model.layers.2.input_layernorm.weight', 'model.language_model.layers.2.post_attention_layernorm.weight', 'model.language_model.layers.3.self_attn.q_proj.weight', 'model.language_model.layers.3.self_attn.q_proj.bias', 'model.language_model.layers.3.self_attn.k_proj.weight', 'model.language_model.layers.3.self_attn.k_proj.bias', 'model.language_model.layers.3.self_attn.v_proj.weight', 'model.language_model.layers.3.self_attn.v_proj.bias', 'model.language_model.layers.3.self_attn.o_proj.weight', 'model.language_model.layers.3.mlp.gate_proj.weight', 'model.language_model.layers.3.mlp.up_proj.weight', 'model.language_model.layers.3.mlp.down_proj.weight', 'model.language_model.layers.3.input_layernorm.weight', 'model.language_model.layers.3.post_attention_layernorm.weight', 'model.language_model.layers.4.self_attn.q_proj.weight', 'model.language_model.layers.4.self_attn.q_proj.bias', 'model.language_model.layers.4.self_attn.k_proj.weight', 'model.language_model.layers.4.self_attn.k_proj.bias', 'model.language_model.layers.4.self_attn.v_proj.weight', 'model.language_model.layers.4.self_attn.v_proj.bias', 'model.language_model.layers.4.self_attn.o_proj.weight', 'model.language_model.layers.4.mlp.gate_proj.weight', 'model.language_model.layers.4.mlp.up_proj.weight', 'model.language_model.layers.4.mlp.down_proj.weight', 'model.language_model.layers.4.input_layernorm.weight', 'model.language_model.layers.4.post_attention_layernorm.weight', 'model.language_model.layers.5.self_attn.q_proj.weight', 'model.language_model.layers.5.self_attn.q_proj.bias', 'model.language_model.layers.5.self_attn.k_proj.weight', 'model.language_model.layers.5.self_attn.k_proj.bias', 'model.language_model.layers.5.self_attn.v_proj.weight', 'model.language_model.layers.5.self_attn.v_proj.bias', 'model.language_model.layers.5.self_attn.o_proj.weight', 'model.language_model.layers.5.mlp.gate_proj.weight', 'model.language_model.layers.5.mlp.up_proj.weight', 'model.language_model.layers.5.mlp.down_proj.weight', 'model.language_model.layers.5.input_layernorm.weight', 'model.language_model.layers.5.post_attention_layernorm.weight', 'model.language_model.layers.6.self_attn.q_proj.weight', 'model.language_model.layers.6.self_attn.q_proj.bias', 'model.language_model.layers.6.self_attn.k_proj.weight', 'model.language_model.layers.6.self_attn.k_proj.bias', 'model.language_model.layers.6.self_attn.v_proj.weight', 'model.language_model.layers.6.self_attn.v_proj.bias', 'model.language_model.layers.6.self_attn.o_proj.weight', 'model.language_model.layers.6.mlp.gate_proj.weight', 'model.language_model.layers.6.mlp.up_proj.weight', 'model.language_model.layers.6.mlp.down_proj.weight', 'model.language_model.layers.6.input_layernorm.weight', 'model.language_model.layers.6.post_attention_layernorm.weight', 'model.language_model.layers.7.self_attn.q_proj.weight', 'model.language_model.layers.7.self_attn.q_proj.bias', 'model.language_model.layers.7.self_attn.k_proj.weight', 'model.language_model.layers.7.self_attn.k_proj.bias', 'model.language_model.layers.7.self_attn.v_proj.weight', 'model.language_model.layers.7.self_attn.v_proj.bias', 'model.language_model.layers.7.self_attn.o_proj.weight', 'model.language_model.layers.7.mlp.gate_proj.weight', 'model.language_model.layers.7.mlp.up_proj.weight', 'model.language_model.layers.7.mlp.down_proj.weight', 'model.language_model.layers.7.input_layernorm.weight', 'model.language_model.layers.7.post_attention_layernorm.weight', 'model.language_model.layers.8.self_attn.q_proj.weight', 'model.language_model.layers.8.self_attn.q_proj.bias', 'model.language_model.layers.8.self_attn.k_proj.weight', 'model.language_model.layers.8.self_attn.k_proj.bias', 'model.language_model.layers.8.self_attn.v_proj.weight', 'model.language_model.layers.8.self_attn.v_proj.bias', 'model.language_model.layers.8.self_attn.o_proj.weight', 'model.language_model.layers.8.mlp.gate_proj.weight', 'model.language_model.layers.8.mlp.up_proj.weight', 'model.language_model.layers.8.mlp.down_proj.weight', 'model.language_model.layers.8.input_layernorm.weight', 'model.language_model.layers.8.post_attention_layernorm.weight', 'model.language_model.layers.9.self_attn.q_proj.weight', 'model.language_model.layers.9.self_attn.q_proj.bias', 'model.language_model.layers.9.self_attn.k_proj.weight', 'model.language_model.layers.9.self_attn.k_proj.bias', 'model.language_model.layers.9.self_attn.v_proj.weight', 'model.language_model.layers.9.self_attn.v_proj.bias', 'model.language_model.layers.9.self_attn.o_proj.weight', 'model.language_model.layers.9.mlp.gate_proj.weight', 'model.language_model.layers.9.mlp.up_proj.weight', 'model.language_model.layers.9.mlp.down_proj.weight', 'model.language_model.layers.9.input_layernorm.weight', 'model.language_model.layers.9.post_attention_layernorm.weight', 'model.language_model.layers.10.self_attn.q_proj.weight', 'model.language_model.layers.10.self_attn.q_proj.bias', 'model.language_model.layers.10.self_attn.k_proj.weight', 'model.language_model.layers.10.self_attn.k_proj.bias', 'model.language_model.layers.10.self_attn.v_proj.weight', 'model.language_model.layers.10.self_attn.v_proj.bias', 'model.language_model.layers.10.self_attn.o_proj.weight', 'model.language_model.layers.10.mlp.gate_proj.weight', 'model.language_model.layers.10.mlp.up_proj.weight', 'model.language_model.layers.10.mlp.down_proj.weight', 'model.language_model.layers.10.input_layernorm.weight', 'model.language_model.layers.10.post_attention_layernorm.weight', 'model.language_model.layers.11.self_attn.q_proj.weight', 'model.language_model.layers.11.self_attn.q_proj.bias', 'model.language_model.layers.11.self_attn.k_proj.weight', 'model.language_model.layers.11.self_attn.k_proj.bias', 'model.language_model.layers.11.self_attn.v_proj.weight', 'model.language_model.layers.11.self_attn.v_proj.bias', 'model.language_model.layers.11.self_attn.o_proj.weight', 'model.language_model.layers.11.mlp.gate_proj.weight', 'model.language_model.layers.11.mlp.up_proj.weight', 'model.language_model.layers.11.mlp.down_proj.weight', 'model.language_model.layers.11.input_layernorm.weight', 'model.language_model.layers.11.post_attention_layernorm.weight', 'model.language_model.layers.12.self_attn.q_proj.weight', 'model.language_model.layers.12.self_attn.q_proj.bias', 'model.language_model.layers.12.self_attn.k_proj.weight', 'model.language_model.layers.12.self_attn.k_proj.bias', 'model.language_model.layers.12.self_attn.v_proj.weight', 'model.language_model.layers.12.self_attn.v_proj.bias', 'model.language_model.layers.12.self_attn.o_proj.weight', 'model.language_model.layers.12.mlp.gate_proj.weight', 'model.language_model.layers.12.mlp.up_proj.weight', 'model.language_model.layers.12.mlp.down_proj.weight', 'model.language_model.layers.12.input_layernorm.weight', 'model.language_model.layers.12.post_attention_layernorm.weight', 'model.language_model.layers.13.self_attn.q_proj.weight', 'model.language_model.layers.13.self_attn.q_proj.bias', 'model.language_model.layers.13.self_attn.k_proj.weight', 'model.language_model.layers.13.self_attn.k_proj.bias', 'model.language_model.layers.13.self_attn.v_proj.weight', 'model.language_model.layers.13.self_attn.v_proj.bias', 'model.language_model.layers.13.self_attn.o_proj.weight', 'model.language_model.layers.13.mlp.gate_proj.weight', 'model.language_model.layers.13.mlp.up_proj.weight', 'model.language_model.layers.13.mlp.down_proj.weight', 'model.language_model.layers.13.input_layernorm.weight', 'model.language_model.layers.13.post_attention_layernorm.weight', 'model.language_model.layers.14.self_attn.q_proj.weight', 'model.language_model.layers.14.self_attn.q_proj.bias', 'model.language_model.layers.14.self_attn.k_proj.weight', 'model.language_model.layers.14.self_attn.k_proj.bias', 'model.language_model.layers.14.self_attn.v_proj.weight', 'model.language_model.layers.14.self_attn.v_proj.bias', 'model.language_model.layers.14.self_attn.o_proj.weight', 'model.language_model.layers.14.mlp.gate_proj.weight', 'model.language_model.layers.14.mlp.up_proj.weight', 'model.language_model.layers.14.mlp.down_proj.weight', 'model.language_model.layers.14.input_layernorm.weight', 'model.language_model.layers.14.post_attention_layernorm.weight', 'model.language_model.layers.15.self_attn.q_proj.weight', 'model.language_model.layers.15.self_attn.q_proj.bias', 'model.language_model.layers.15.self_attn.k_proj.weight', 'model.language_model.layers.15.self_attn.k_proj.bias', 'model.language_model.layers.15.self_attn.v_proj.weight', 'model.language_model.layers.15.self_attn.v_proj.bias', 'model.language_model.layers.15.self_attn.o_proj.weight', 'model.language_model.layers.15.mlp.gate_proj.weight', 'model.language_model.layers.15.mlp.up_proj.weight', 'model.language_model.layers.15.mlp.down_proj.weight', 'model.language_model.layers.15.input_layernorm.weight', 'model.language_model.layers.15.post_attention_layernorm.weight', 'model.language_model.layers.16.self_attn.q_proj.weight', 'model.language_model.layers.16.self_attn.q_proj.bias', 'model.language_model.layers.16.self_attn.k_proj.weight', 'model.language_model.layers.16.self_attn.k_proj.bias', 'model.language_model.layers.16.self_attn.v_proj.weight', 'model.language_model.layers.16.self_attn.v_proj.bias', 'model.language_model.layers.16.self_attn.o_proj.weight', 'model.language_model.layers.16.mlp.gate_proj.weight', 'model.language_model.layers.16.mlp.up_proj.weight', 'model.language_model.layers.16.mlp.down_proj.weight', 'model.language_model.layers.16.input_layernorm.weight', 'model.language_model.layers.16.post_attention_layernorm.weight', 'model.language_model.layers.17.self_attn.q_proj.weight', 'model.language_model.layers.17.self_attn.q_proj.bias', 'model.language_model.layers.17.self_attn.k_proj.weight', 'model.language_model.layers.17.self_attn.k_proj.bias', 'model.language_model.layers.17.self_attn.v_proj.weight', 'model.language_model.layers.17.self_attn.v_proj.bias', 'model.language_model.layers.17.self_attn.o_proj.weight', 'model.language_model.layers.17.mlp.gate_proj.weight', 'model.language_model.layers.17.mlp.up_proj.weight', 'model.language_model.layers.17.mlp.down_proj.weight', 'model.language_model.layers.17.input_layernorm.weight', 'model.language_model.layers.17.post_attention_layernorm.weight', 'model.language_model.layers.18.self_attn.q_proj.weight', 'model.language_model.layers.18.self_attn.q_proj.bias', 'model.language_model.layers.18.self_attn.k_proj.weight', 'model.language_model.layers.18.self_attn.k_proj.bias', 'model.language_model.layers.18.self_attn.v_proj.weight', 'model.language_model.layers.18.self_attn.v_proj.bias', 'model.language_model.layers.18.self_attn.o_proj.weight', 'model.language_model.layers.18.mlp.gate_proj.weight', 'model.language_model.layers.18.mlp.up_proj.weight', 'model.language_model.layers.18.mlp.down_proj.weight', 'model.language_model.layers.18.input_layernorm.weight', 'model.language_model.layers.18.post_attention_layernorm.weight', 'model.language_model.layers.19.self_attn.q_proj.weight', 'model.language_model.layers.19.self_attn.q_proj.bias', 'model.language_model.layers.19.self_attn.k_proj.weight', 'model.language_model.layers.19.self_attn.k_proj.bias', 'model.language_model.layers.19.self_attn.v_proj.weight', 'model.language_model.layers.19.self_attn.v_proj.bias', 'model.language_model.layers.19.self_attn.o_proj.weight', 'model.language_model.layers.19.mlp.gate_proj.weight', 'model.language_model.layers.19.mlp.up_proj.weight', 'model.language_model.layers.19.mlp.down_proj.weight', 'model.language_model.layers.19.input_layernorm.weight', 'model.language_model.layers.19.post_attention_layernorm.weight', 'model.language_model.layers.20.self_attn.q_proj.weight', 'model.language_model.layers.20.self_attn.q_proj.bias', 'model.language_model.layers.20.self_attn.k_proj.weight', 'model.language_model.layers.20.self_attn.k_proj.bias', 'model.language_model.layers.20.self_attn.v_proj.weight', 'model.language_model.layers.20.self_attn.v_proj.bias', 'model.language_model.layers.20.self_attn.o_proj.weight', 'model.language_model.layers.20.mlp.gate_proj.weight', 'model.language_model.layers.20.mlp.up_proj.weight', 'model.language_model.layers.20.mlp.down_proj.weight', 'model.language_model.layers.20.input_layernorm.weight', 'model.language_model.layers.20.post_attention_layernorm.weight', 'model.language_model.layers.21.self_attn.q_proj.weight', 'model.language_model.layers.21.self_attn.q_proj.bias', 'model.language_model.layers.21.self_attn.k_proj.weight', 'model.language_model.layers.21.self_attn.k_proj.bias', 'model.language_model.layers.21.self_attn.v_proj.weight', 'model.language_model.layers.21.self_attn.v_proj.bias', 'model.language_model.layers.21.self_attn.o_proj.weight', 'model.language_model.layers.21.mlp.gate_proj.weight', 'model.language_model.layers.21.mlp.up_proj.weight', 'model.language_model.layers.21.mlp.down_proj.weight', 'model.language_model.layers.21.input_layernorm.weight', 'model.language_model.layers.21.post_attention_layernorm.weight', 'model.language_model.layers.22.self_attn.q_proj.weight', 'model.language_model.layers.22.self_attn.q_proj.bias', 'model.language_model.layers.22.self_attn.k_proj.weight', 'model.language_model.layers.22.self_attn.k_proj.bias', 'model.language_model.layers.22.self_attn.v_proj.weight', 'model.language_model.layers.22.self_attn.v_proj.bias', 'model.language_model.layers.22.self_attn.o_proj.weight', 'model.language_model.layers.22.mlp.gate_proj.weight', 'model.language_model.layers.22.mlp.up_proj.weight', 'model.language_model.layers.22.mlp.down_proj.weight', 'model.language_model.layers.22.input_layernorm.weight', 'model.language_model.layers.22.post_attention_layernorm.weight', 'model.language_model.layers.23.self_attn.q_proj.weight', 'model.language_model.layers.23.self_attn.q_proj.bias', 'model.language_model.layers.23.self_attn.k_proj.weight', 'model.language_model.layers.23.self_attn.k_proj.bias', 'model.language_model.layers.23.self_attn.v_proj.weight', 'model.language_model.layers.23.self_attn.v_proj.bias', 'model.language_model.layers.23.self_attn.o_proj.weight', 'model.language_model.layers.23.mlp.gate_proj.weight', 'model.language_model.layers.23.mlp.up_proj.weight', 'model.language_model.layers.23.mlp.down_proj.weight', 'model.language_model.layers.23.input_layernorm.weight', 'model.language_model.layers.23.post_attention_layernorm.weight', 'model.language_model.layers.24.self_attn.q_proj.weight', 'model.language_model.layers.24.self_attn.q_proj.bias', 'model.language_model.layers.24.self_attn.k_proj.weight', 'model.language_model.layers.24.self_attn.k_proj.bias', 'model.language_model.layers.24.self_attn.v_proj.weight', 'model.language_model.layers.24.self_attn.v_proj.bias', 'model.language_model.layers.24.self_attn.o_proj.weight', 'model.language_model.layers.24.mlp.gate_proj.weight', 'model.language_model.layers.24.mlp.up_proj.weight', 'model.language_model.layers.24.mlp.down_proj.weight', 'model.language_model.layers.24.input_layernorm.weight', 'model.language_model.layers.24.post_attention_layernorm.weight', 'model.language_model.layers.25.self_attn.q_proj.weight', 'model.language_model.layers.25.self_attn.q_proj.bias', 'model.language_model.layers.25.self_attn.k_proj.weight', 'model.language_model.layers.25.self_attn.k_proj.bias', 'model.language_model.layers.25.self_attn.v_proj.weight', 'model.language_model.layers.25.self_attn.v_proj.bias', 'model.language_model.layers.25.self_attn.o_proj.weight', 'model.language_model.layers.25.mlp.gate_proj.weight', 'model.language_model.layers.25.mlp.up_proj.weight', 'model.language_model.layers.25.mlp.down_proj.weight', 'model.language_model.layers.25.input_layernorm.weight', 'model.language_model.layers.25.post_attention_layernorm.weight', 'model.language_model.layers.26.self_attn.q_proj.weight', 'model.language_model.layers.26.self_attn.q_proj.bias', 'model.language_model.layers.26.self_attn.k_proj.weight', 'model.language_model.layers.26.self_attn.k_proj.bias', 'model.language_model.layers.26.self_attn.v_proj.weight', 'model.language_model.layers.26.self_attn.v_proj.bias', 'model.language_model.layers.26.self_attn.o_proj.weight', 'model.language_model.layers.26.mlp.gate_proj.weight', 'model.language_model.layers.26.mlp.up_proj.weight', 'model.language_model.layers.26.mlp.down_proj.weight', 'model.language_model.layers.26.input_layernorm.weight', 'model.language_model.layers.26.post_attention_layernorm.weight', 'model.language_model.layers.27.self_attn.q_proj.weight', 'model.language_model.layers.27.self_attn.q_proj.bias', 'model.language_model.layers.27.self_attn.k_proj.weight', 'model.language_model.layers.27.self_attn.k_proj.bias', 'model.language_model.layers.27.self_attn.v_proj.weight', 'model.language_model.layers.27.self_attn.v_proj.bias', 'model.language_model.layers.27.self_attn.o_proj.weight', 'model.language_model.layers.27.mlp.gate_proj.weight', 'model.language_model.layers.27.mlp.up_proj.weight', 'model.language_model.layers.27.mlp.down_proj.weight', 'model.language_model.layers.27.input_layernorm.weight', 'model.language_model.layers.27.post_attention_layernorm.weight', 'model.language_model.norm.weight', 'lm_head.weight'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29794f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2_5_VLForConditionalGeneration(\n",
       "  (model): Qwen2_5_VLModel(\n",
       "    (visual): Qwen2_5_VisionTransformerPretrainedModel(\n",
       "      (patch_embed): Qwen2_5_VisionPatchEmbed(\n",
       "        (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
       "      )\n",
       "      (rotary_pos_emb): Qwen2_5_VisionRotaryEmbedding()\n",
       "      (blocks): ModuleList(\n",
       "        (0-31): 32 x Qwen2_5_VLVisionBlock(\n",
       "          (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "          (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "          (attn): Qwen2_5_VLVisionAttention(\n",
       "            (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "            (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (mlp): Qwen2_5_VLMLP(\n",
       "            (gate_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
       "            (up_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
       "            (down_proj): Linear(in_features=3420, out_features=1280, bias=True)\n",
       "            (act_fn): SiLUActivation()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (merger): Qwen2_5_VLPatchMerger(\n",
       "        (ln_q): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (language_model): Qwen2_5_VLTextModel(\n",
       "      (embed_tokens): Embedding(152064, 3584)\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x Qwen2_5_VLDecoderLayer(\n",
       "          (self_attn): Qwen2_5_VLAttention(\n",
       "            (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "            (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "            (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "            (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "            (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "            (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "            (act_fn): SiLUActivation()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "      (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b02483",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c2e9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1624, 3584])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "iterations = 32\n",
    "quant_type = None # \"int8wo\" \"int4wo\" \"fp8row\"\n",
    "if quant_type:\n",
    "    simple_quantize_model(text_encoder, quant_type)\n",
    "\n",
    "all_embeds = []\n",
    "for i in range(iterations):\n",
    "    prompt_embeds, prompt_embeds_mask = encode_prompt(\n",
    "        foundation.text_encoder,\n",
    "        foundation.pipe.tokenizer,\n",
    "        inps[i][\"prompt\"],\n",
    "        device=\"cuda\",\n",
    "        dtype=foundation.dtype,\n",
    "        max_sequence_length = foundation.config.train_max_sequence_length,\n",
    "    )\n",
    "    all_embeds.append(prompt_embeds.squeeze(0))\n",
    "stacked_embd = torch.cat(all_embeds, dim=0)\n",
    "print(f\"{stacked_embd.shape}\")\n",
    "torch.save(stacked_embd, f\"{quant_type or 'base'}_stacked_embd_{iterations}.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1, 59, 3584]),\n",
       " torch.Size([1, 1, 41, 3584]),\n",
       " torch.Size([1, 1, 58, 3584]),\n",
       " torch.Size([1, 1, 76, 3584]),\n",
       " torch.Size([1, 1, 32, 3584]),\n",
       " torch.Size([1, 1, 42, 3584]),\n",
       " torch.Size([1, 1, 75, 3584]),\n",
       " torch.Size([1, 1, 69, 3584]),\n",
       " torch.Size([1, 1, 42, 3584]),\n",
       " torch.Size([1, 1, 40, 3584]),\n",
       " torch.Size([1, 1, 76, 3584]),\n",
       " torch.Size([1, 1, 60, 3584]),\n",
       " torch.Size([1, 1, 34, 3584]),\n",
       " torch.Size([1, 1, 75, 3584]),\n",
       " torch.Size([1, 1, 58, 3584]),\n",
       " torch.Size([1, 1, 76, 3584]),\n",
       " torch.Size([1, 1, 60, 3584]),\n",
       " torch.Size([1, 1, 37, 3584]),\n",
       " torch.Size([1, 1, 52, 3584]),\n",
       " torch.Size([1, 1, 40, 3584]),\n",
       " torch.Size([1, 1, 41, 3584]),\n",
       " torch.Size([1, 1, 70, 3584]),\n",
       " torch.Size([1, 1, 56, 3584]),\n",
       " torch.Size([1, 1, 24, 3584]),\n",
       " torch.Size([1, 1, 20, 3584]),\n",
       " torch.Size([1, 1, 38, 3584]),\n",
       " torch.Size([1, 1, 51, 3584]),\n",
       " torch.Size([1, 1, 14, 3584]),\n",
       " torch.Size([1, 1, 69, 3584]),\n",
       " torch.Size([1, 1, 42, 3584]),\n",
       " torch.Size([1, 1, 56, 3584]),\n",
       " torch.Size([1, 1, 41, 3584])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.shape for s in all_embeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43be3d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Tokenizer(name_or_path='/home/ubuntu/.cache/huggingface/hub/models--Qwen--Qwen-Image-Edit-2509/snapshots/d3968ef930e841f4c73640fb8afa3b306a78167e/tokenizer', vocab_size=151643, model_max_length=131072, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foundation.pipe.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4872b9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_added_tokens_decoder',\n",
       " '_added_tokens_encoder',\n",
       " '_auto_class',\n",
       " '_batch_encode_plus',\n",
       " '_batch_prepare_for_model',\n",
       " '_call_one',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_repo',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_eventually_correct_t5_max_length',\n",
       " '_from_pretrained',\n",
       " '_get_files_timestamps',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_in_target_context_manager',\n",
       " '_pad',\n",
       " '_pad_token_type_id',\n",
       " '_processor_class',\n",
       " '_save_pretrained',\n",
       " '_set_model_specific_special_tokens',\n",
       " '_set_processor_class',\n",
       " '_special_tokens_map',\n",
       " '_switch_to_input_mode',\n",
       " '_switch_to_target_mode',\n",
       " '_tokenize',\n",
       " '_update_total_vocab_size',\n",
       " '_update_trie',\n",
       " '_upload_modified_files',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'added_tokens_decoder',\n",
       " 'added_tokens_encoder',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'apply_chat_template',\n",
       " 'as_target_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'bpe',\n",
       " 'bpe_ranks',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'byte_decoder',\n",
       " 'byte_encoder',\n",
       " 'cache',\n",
       " 'chat_template',\n",
       " 'clean_up_tokenization',\n",
       " 'clean_up_tokenization_spaces',\n",
       " 'convert_added_tokens',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'deprecation_warnings',\n",
       " 'encode',\n",
       " 'encode_message_with_chat_template',\n",
       " 'encode_plus',\n",
       " 'encoder',\n",
       " 'errors',\n",
       " 'extra_special_tokens',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_chat_template',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'pat',\n",
       " 'prepare_for_model',\n",
       " 'prepare_for_tokenization',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_chat_templates',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'split_special_tokens',\n",
       " 'tokenize',\n",
       " 'tokens_trie',\n",
       " 'total_vocab_size',\n",
       " 'truncate_sequences',\n",
       " 'truncation_side',\n",
       " 'verbose',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(foundation.pipe.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c65ac03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 683, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 63.53046417236328\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.7777, -1.7632, -1.7631,  ..., -0.5286, -0.6148, -0.7006],\n",
      "        [-1.7381, -1.7182, -1.7566,  ..., -0.9265, -0.9171, -0.9117],\n",
      "        [-1.7631, -1.7485, -1.7555,  ..., -0.4396, -0.4960, -0.5632],\n",
      "        ...,\n",
      "        [-1.6908, -1.7087, -1.7196,  ..., -0.5421, -0.5706, -0.5549],\n",
      "        [-1.7173, -1.7147, -1.6992,  ..., -0.7265, -0.7266, -0.7266],\n",
      "        [-1.7319, -1.7304, -1.7315,  ..., -0.6268, -0.6268, -0.5985]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 48, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3552, 1176)\n",
      "Min: -1.8659758567810059, Max: 2.1775243282318115, Mean: -0.7494064569473267\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 954, 3584)\n",
      "Min: -188.0, Max: 127.5, Mean: -0.11572265625\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.23725280002690852 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 768, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 107.94649505615234\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[ 0.5428,  0.5998,  0.6863,  ...,  0.8736,  0.9324,  0.9669],\n",
      "        [ 0.7459,  0.6964,  0.6597,  ...,  0.7373,  0.6676,  0.6491],\n",
      "        [-0.1431, -0.0794, -0.0050,  ...,  1.0617,  1.0885,  1.0392],\n",
      "        ...,\n",
      "        [-1.1572, -1.0803, -0.8879,  ..., -0.9471, -1.0033, -1.0551],\n",
      "        [-0.3540, -0.3737, -0.3771,  ...,  0.5403,  0.6746,  0.5794],\n",
      "        [-0.5961, -0.6764, -0.7813,  ...,  0.2935,  0.2378,  0.1684]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 54, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3996, 1176)\n",
      "Min: -1.7068719863891602, Max: 2.0894978046417236, Mean: -0.09713771194219589\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1047, 3584)\n",
      "Min: -179.0, Max: 126.0, Mean: -0.099609375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.2631705839885399 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 768, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 107.94649505615234\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[ 0.5428,  0.5998,  0.6863,  ...,  0.8736,  0.9324,  0.9669],\n",
      "        [ 0.7459,  0.6964,  0.6597,  ...,  0.7373,  0.6676,  0.6491],\n",
      "        [-0.1431, -0.0794, -0.0050,  ...,  1.0617,  1.0885,  1.0392],\n",
      "        ...,\n",
      "        [-1.1572, -1.0803, -0.8879,  ..., -0.9471, -1.0033, -1.0551],\n",
      "        [-0.3540, -0.3737, -0.3771,  ...,  0.5403,  0.6746,  0.5794],\n",
      "        [-0.5961, -0.6764, -0.7813,  ...,  0.2935,  0.2378,  0.1684]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 54, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3996, 1176)\n",
      "Min: -1.7068719863891602, Max: 2.0894978046417236, Mean: -0.09713771194219589\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1064, 3584)\n",
      "Min: -179.0, Max: 128.0, Mean: -0.099609375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.2707125770393759 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 575, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 63.50874710083008\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  74785,    279,   1376,   4419,    315,    279,\n",
      "           1946,   2168,    320,   3423,     11,   6083,     11,   1379,     11,\n",
      "          10434,     11,   6171,     11,   4004,    701,   1221,  10339,   1246,\n",
      "            279,   1196,    594,   1467,   7600,   1265,  11596,    476,   5602,\n",
      "            279,   2168,     13,  19813,    264,    501,   2168,    429,  20027,\n",
      "            279,   1196,    594,   8502,   1393,  20337,  28137,    448,    279,\n",
      "           4024,   1946,   1380,   8311,     13, 151645,    198, 151644,    872,\n",
      "            198,  24669,    220,     16,     25,    220, 151652, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151653,  44063, 105995,  69041,  77559, 108215,     19,     20,\n",
      "          26381,  49720,    279,   6249,    220,     19,     20,  12348,    311,\n",
      "            279,   2115,     13,  58230,    228, 105995,  46670,  17714,  65278,\n",
      "          61443, 105995,  11999,    279,   6249,    311,    264,   3265,   5239,\n",
      "             13,  58230,    228, 107620, 110697,  26939, 102690,  57452, 107372,\n",
      "          11999,    279,   6249,    311,    264,  34211,    594,  46697,   1651,\n",
      "             13,    220,  58230,    228, 105995,  46670,  17714,  80942,  63836,\n",
      "         105995,  11999,    279,   6249,    311,    264,   6884,  34381,  18342,\n",
      "             13, 151645,    198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.2809, -1.3385, -1.3964,  ..., -1.2787, -1.2597, -1.2751],\n",
      "        [-1.5183, -1.4832, -1.5793,  ..., -1.3038, -1.3043, -1.3074],\n",
      "        [-1.3133, -1.3185, -1.2903,  ..., -1.3487, -1.3452, -1.3598],\n",
      "        ...,\n",
      "        [-1.6626, -1.6774, -1.6764,  ..., -1.3340, -1.3299, -1.3187],\n",
      "        [-1.6502, -1.6630, -1.6645,  ..., -1.3067, -1.2753, -1.2526],\n",
      "        [-1.6754, -1.6748, -1.6749,  ..., -1.3378, -1.3236, -1.3238]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 42, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3108, 1176)\n",
      "Min: -1.8282335996627808, Max: 2.168954372406006, Mean: -0.7451295256614685\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 860, 3584)\n",
      "Min: -181.0, Max: 128.0, Mean: -0.130859375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.23752214293926954 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 512, 896)\n",
      "Min: 0.0, Max: 255.0, Mean: 127.4706802368164\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  74785,    279,   1376,   4419,    315,    279,\n",
      "           1946,   2168,    320,   3423,     11,   6083,     11,   1379,     11,\n",
      "          10434,     11,   6171,     11,   4004,    701,   1221,  10339,   1246,\n",
      "            279,   1196,    594,   1467,   7600,   1265,  11596,    476,   5602,\n",
      "            279,   2168,     13,  19813,    264,    501,   2168,    429,  20027,\n",
      "            279,   1196,    594,   8502,   1393,  20337,  28137,    448,    279,\n",
      "           4024,   1946,   1380,   8311,     13, 151645,    198, 151644,    872,\n",
      "            198,  24669,    220,     16,     25,    220, 151652, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653,  44063,\n",
      "         105995, 106315, 101148,  14561,    279,   6249,   4637,     13,    220,\n",
      "          58230,    228, 105995,  46670,  17714,  80942,  63836, 105995,  11999,\n",
      "            279,   6249,    311,    264,   6884,  34381,  18342,     13, 151645,\n",
      "            198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[1.0544, 1.0398, 0.9960,  ..., 1.4028, 1.4420, 1.4439],\n",
      "        [1.0690, 1.0690, 1.0690,  ..., 1.4382, 1.4361, 1.4336],\n",
      "        [1.0948, 1.1056, 1.1284,  ..., 1.4509, 1.4499, 1.4431],\n",
      "        ...,\n",
      "        [0.5789, 0.5943, 0.6037,  ..., 0.7682, 0.7563, 0.7712],\n",
      "        [0.3476, 0.3538, 0.4004,  ..., 0.5106, 0.5245, 0.4960],\n",
      "        [0.4727, 0.4748, 0.4720,  ..., 0.6245, 0.6248, 0.6248]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 36, 64]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (2304, 1176)\n",
      "Min: -1.8204282522201538, Max: 2.206862211227417, Mean: 0.18789313733577728\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 615, 3584)\n",
      "Min: -189.0, Max: 126.0, Mean: -0.1318359375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.1779305540258065 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 1024, 812)\n",
      "Min: 0.0, Max: 255.0, Mean: 159.07200622558594\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-0.1280, -0.1572, -0.1718,  ...,  0.0113,  0.0130,  0.0130],\n",
      "        [-0.1280, -0.1280, -0.0842,  ...,  0.0413,  0.0413,  0.0413],\n",
      "        [-0.1426, -0.1572, -0.1718,  ...,  0.0516,  0.0560,  0.0516],\n",
      "        ...,\n",
      "        [ 1.5946,  1.5946,  1.5946,  ...,  1.8331,  1.8331,  1.8188],\n",
      "        [ 1.6100,  1.6100,  1.6100,  ...,  1.1334,  1.1334,  1.1334],\n",
      "        [ 1.6100,  1.6100,  1.6092,  ...,  1.1050,  1.1050,  1.1050]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 74, 58]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (4292, 1176)\n",
      "Min: -1.7411859035491943, Max: 2.1950085163116455, Mean: 0.6495240926742554\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1122, 3584)\n",
      "Min: -176.0, Max: 134.0, Mean: -0.142578125\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.2897540549747646 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 711, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 113.62726593017578\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.2667, -1.2667, -1.2667,  ..., -0.8217, -0.8335, -0.8606],\n",
      "        [-1.3121, -1.3076, -1.3473,  ..., -1.1973, -1.1864, -1.1730],\n",
      "        [-1.1496, -1.1381, -1.1240,  ..., -0.6462, -0.6098, -0.6079],\n",
      "        ...,\n",
      "        [ 1.0859, -0.1256, -0.2868,  ...,  0.6197,  0.4291,  0.0579],\n",
      "        [-1.1702, -1.0602, -0.5905,  ...,  0.6149, -0.1937, -1.1534],\n",
      "        [-1.6150, -0.8690,  0.2011,  ...,  0.5735,  0.3593,  0.0601]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 50, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3700, 1176)\n",
      "Min: -1.8720948696136475, Max: 2.249417543411255, Mean: -0.012816129252314568\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1007, 3584)\n",
      "Min: -186.0, Max: 135.0, Mean: -0.1396484375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.25078090804163367 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 711, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 113.62726593017578\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.2667, -1.2667, -1.2667,  ..., -0.8217, -0.8335, -0.8606],\n",
      "        [-1.3121, -1.3076, -1.3473,  ..., -1.1973, -1.1864, -1.1730],\n",
      "        [-1.1496, -1.1381, -1.1240,  ..., -0.6462, -0.6098, -0.6079],\n",
      "        ...,\n",
      "        [ 1.0859, -0.1256, -0.2868,  ...,  0.6197,  0.4291,  0.0579],\n",
      "        [-1.1702, -1.0602, -0.5905,  ...,  0.6149, -0.1937, -1.1534],\n",
      "        [-1.6150, -0.8690,  0.2011,  ...,  0.5735,  0.3593,  0.0601]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 50, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3700, 1176)\n",
      "Min: -1.8720948696136475, Max: 2.249417543411255, Mean: -0.012816129252314568\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1001, 3584)\n",
      "Min: -186.0, Max: 135.0, Mean: -0.1396484375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.24992003594525158 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 512, 896)\n",
      "Min: 0.0, Max: 255.0, Mean: 127.4706802368164\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  74785,    279,   1376,   4419,    315,    279,\n",
      "           1946,   2168,    320,   3423,     11,   6083,     11,   1379,     11,\n",
      "          10434,     11,   6171,     11,   4004,    701,   1221,  10339,   1246,\n",
      "            279,   1196,    594,   1467,   7600,   1265,  11596,    476,   5602,\n",
      "            279,   2168,     13,  19813,    264,    501,   2168,    429,  20027,\n",
      "            279,   1196,    594,   8502,   1393,  20337,  28137,    448,    279,\n",
      "           4024,   1946,   1380,   8311,     13, 151645,    198, 151644,    872,\n",
      "            198,  24669,    220,     16,     25,    220, 151652, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653,  44063,\n",
      "         105995,  69041,  77559, 108215,     19,     20,  26381,  49720,    279,\n",
      "           6249,    220,     19,     20,  12348,    311,    279,   2115,     13,\n",
      "            220,  58230,    228, 105995,  46670,  17714,  80942,  63836, 105995,\n",
      "          11999,    279,   6249,    311,    264,   6884,  34381,  18342,     13,\n",
      "         151645,    198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[1.0544, 1.0398, 0.9960,  ..., 1.4028, 1.4420, 1.4439],\n",
      "        [1.0690, 1.0690, 1.0690,  ..., 1.4382, 1.4361, 1.4336],\n",
      "        [1.0948, 1.1056, 1.1284,  ..., 1.4509, 1.4499, 1.4431],\n",
      "        ...,\n",
      "        [0.5789, 0.5943, 0.6037,  ..., 0.7682, 0.7563, 0.7712],\n",
      "        [0.3476, 0.3538, 0.4004,  ..., 0.5106, 0.5245, 0.4960],\n",
      "        [0.4727, 0.4748, 0.4720,  ..., 0.6245, 0.6248, 0.6248]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 36, 64]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (2304, 1176)\n",
      "Min: -1.8204282522201538, Max: 2.206862211227417, Mean: 0.18789313733577728\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 625, 3584)\n",
      "Min: -189.0, Max: 127.5, Mean: -0.1328125\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.1791253340197727 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 575, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 63.50874710083008\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  74785,    279,   1376,   4419,    315,    279,\n",
      "           1946,   2168,    320,   3423,     11,   6083,     11,   1379,     11,\n",
      "          10434,     11,   6171,     11,   4004,    701,   1221,  10339,   1246,\n",
      "            279,   1196,    594,   1467,   7600,   1265,  11596,    476,   5602,\n",
      "            279,   2168,     13,  19813,    264,    501,   2168,    429,  20027,\n",
      "            279,   1196,    594,   8502,   1393,  20337,  28137,    448,    279,\n",
      "           4024,   1946,   1380,   8311,     13, 151645,    198, 151644,    872,\n",
      "            198,  24669,    220,     16,     25,    220, 151652, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151653,  44063, 107620, 110697,  26939, 102690,  57452, 107372,\n",
      "          11999,    279,   6249,    311,    264,  34211,    594,  46697,   1651,\n",
      "             13,    220,  58230,    228, 105995,  46670,  17714,  80942,  63836,\n",
      "         105995,  11999,    279,   6249,    311,    264,   6884,  34381,  18342,\n",
      "             13, 151645,    198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0'), 'pixel_values': tensor([[-1.2809, -1.3385, -1.3964,  ..., -1.2787, -1.2597, -1.2751],\n",
      "        [-1.5183, -1.4832, -1.5793,  ..., -1.3038, -1.3043, -1.3074],\n",
      "        [-1.3133, -1.3185, -1.2903,  ..., -1.3487, -1.3452, -1.3598],\n",
      "        ...,\n",
      "        [-1.6626, -1.6774, -1.6764,  ..., -1.3340, -1.3299, -1.3187],\n",
      "        [-1.6502, -1.6630, -1.6645,  ..., -1.3067, -1.2753, -1.2526],\n",
      "        [-1.6754, -1.6748, -1.6749,  ..., -1.3378, -1.3236, -1.3238]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 42, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3108, 1176)\n",
      "Min: -1.8282335996627808, Max: 2.168954372406006, Mean: -0.7451295256614685\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 824, 3584)\n",
      "Min: -181.0, Max: 131.0, Mean: -0.130859375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.23407166998367757 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 683, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 63.53046417236328\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.7777, -1.7632, -1.7631,  ..., -0.5286, -0.6148, -0.7006],\n",
      "        [-1.7381, -1.7182, -1.7566,  ..., -0.9265, -0.9171, -0.9117],\n",
      "        [-1.7631, -1.7485, -1.7555,  ..., -0.4396, -0.4960, -0.5632],\n",
      "        ...,\n",
      "        [-1.6908, -1.7087, -1.7196,  ..., -0.5421, -0.5706, -0.5549],\n",
      "        [-1.7173, -1.7147, -1.6992,  ..., -0.7265, -0.7266, -0.7266],\n",
      "        [-1.7319, -1.7304, -1.7315,  ..., -0.6268, -0.6268, -0.5985]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 48, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3552, 1176)\n",
      "Min: -1.8659758567810059, Max: 2.1775243282318115, Mean: -0.7494064569473267\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 971, 3584)\n",
      "Min: -188.0, Max: 128.0, Mean: -0.11572265625\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.23473224299959838 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 768, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 107.94649505615234\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[ 0.5428,  0.5998,  0.6863,  ...,  0.8736,  0.9324,  0.9669],\n",
      "        [ 0.7459,  0.6964,  0.6597,  ...,  0.7373,  0.6676,  0.6491],\n",
      "        [-0.1431, -0.0794, -0.0050,  ...,  1.0617,  1.0885,  1.0392],\n",
      "        ...,\n",
      "        [-1.1572, -1.0803, -0.8879,  ..., -0.9471, -1.0033, -1.0551],\n",
      "        [-0.3540, -0.3737, -0.3771,  ...,  0.5403,  0.6746,  0.5794],\n",
      "        [-0.5961, -0.6764, -0.7813,  ...,  0.2935,  0.2378,  0.1684]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 54, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3996, 1176)\n",
      "Min: -1.7068719863891602, Max: 2.0894978046417236, Mean: -0.09713771194219589\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1066, 3584)\n",
      "Min: -179.0, Max: 126.5, Mean: -0.099609375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.26784510200377554 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 1024, 812)\n",
      "Min: 0.0, Max: 255.0, Mean: 159.07200622558594\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-0.1280, -0.1572, -0.1718,  ...,  0.0113,  0.0130,  0.0130],\n",
      "        [-0.1280, -0.1280, -0.0842,  ...,  0.0413,  0.0413,  0.0413],\n",
      "        [-0.1426, -0.1572, -0.1718,  ...,  0.0516,  0.0560,  0.0516],\n",
      "        ...,\n",
      "        [ 1.5946,  1.5946,  1.5946,  ...,  1.8331,  1.8331,  1.8188],\n",
      "        [ 1.6100,  1.6100,  1.6100,  ...,  1.1334,  1.1334,  1.1334],\n",
      "        [ 1.6100,  1.6100,  1.6092,  ...,  1.1050,  1.1050,  1.1050]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 74, 58]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (4292, 1176)\n",
      "Min: -1.7411859035491943, Max: 2.1950085163116455, Mean: 0.6495240926742554\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1114, 3584)\n",
      "Min: -176.0, Max: 129.0, Mean: -0.142578125\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.29315092496108264 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 575, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 63.50874710083008\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  74785,    279,   1376,   4419,    315,    279,\n",
      "           1946,   2168,    320,   3423,     11,   6083,     11,   1379,     11,\n",
      "          10434,     11,   6171,     11,   4004,    701,   1221,  10339,   1246,\n",
      "            279,   1196,    594,   1467,   7600,   1265,  11596,    476,   5602,\n",
      "            279,   2168,     13,  19813,    264,    501,   2168,    429,  20027,\n",
      "            279,   1196,    594,   8502,   1393,  20337,  28137,    448,    279,\n",
      "           4024,   1946,   1380,   8311,     13, 151645,    198, 151644,    872,\n",
      "            198,  24669,    220,     16,     25,    220, 151652, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151653,  44063, 105995,  69041,  64817, 108215,     19,     20,\n",
      "          26381,  49720,    279,   6249,    220,     19,     20,  12348,    311,\n",
      "            279,   1290,     13,  58230,    228, 105995,  46670,  17714,  65278,\n",
      "          61443, 105995,  11999,    279,   6249,    311,    264,   3265,   5239,\n",
      "             13,  58230,    228, 107620, 106438, 100462, 121751, 107372,  11999,\n",
      "            279,   6249,    311,    264,  11958,    594,  46697,   1651,     13,\n",
      "            220,  58230,    228, 105995,  46670,  17714,  80942,  63836, 105995,\n",
      "          11999,    279,   6249,    311,    264,   6884,  34381,  18342,     13,\n",
      "         151645,    198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.2809, -1.3385, -1.3964,  ..., -1.2787, -1.2597, -1.2751],\n",
      "        [-1.5183, -1.4832, -1.5793,  ..., -1.3038, -1.3043, -1.3074],\n",
      "        [-1.3133, -1.3185, -1.2903,  ..., -1.3487, -1.3452, -1.3598],\n",
      "        ...,\n",
      "        [-1.6626, -1.6774, -1.6764,  ..., -1.3340, -1.3299, -1.3187],\n",
      "        [-1.6502, -1.6630, -1.6645,  ..., -1.3067, -1.2753, -1.2526],\n",
      "        [-1.6754, -1.6748, -1.6749,  ..., -1.3378, -1.3236, -1.3238]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 42, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3108, 1176)\n",
      "Min: -1.8282335996627808, Max: 2.168954372406006, Mean: -0.7451295256614685\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 859, 3584)\n",
      "Min: -181.0, Max: 126.5, Mean: -0.130859375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.2358077869284898 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 819, 1024)\n",
      "Min: 5.0, Max: 245.00001525878906, Mean: 73.38787078857422\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.5443, -1.5443, -1.5443,  ..., -1.2811, -1.2811, -1.2811],\n",
      "        [-1.5304, -1.5153, -1.5399,  ..., -1.2807, -1.2811, -1.2811],\n",
      "        [-1.5879, -1.5879, -1.5879,  ..., -1.2811, -1.2811, -1.2811],\n",
      "        ...,\n",
      "        [-1.5606, -1.5608, -1.5594,  ..., -1.2243, -1.2243, -1.2243],\n",
      "        [-1.5721, -1.5686, -1.5575,  ..., -1.3348, -1.3080, -1.3080],\n",
      "        [-1.5571, -1.5433, -1.5442,  ..., -1.2525, -1.2382, -1.2242]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 58, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (4292, 1176)\n",
      "Min: -1.7186729907989502, Max: 2.005134344100952, Mean: -0.602754533290863\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1138, 3584)\n",
      "Min: -166.0, Max: 132.0, Mean: -0.1259765625\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.29242081195116043 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 575, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 63.50874710083008\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  74785,    279,   1376,   4419,    315,    279,\n",
      "           1946,   2168,    320,   3423,     11,   6083,     11,   1379,     11,\n",
      "          10434,     11,   6171,     11,   4004,    701,   1221,  10339,   1246,\n",
      "            279,   1196,    594,   1467,   7600,   1265,  11596,    476,   5602,\n",
      "            279,   2168,     13,  19813,    264,    501,   2168,    429,  20027,\n",
      "            279,   1196,    594,   8502,   1393,  20337,  28137,    448,    279,\n",
      "           4024,   1946,   1380,   8311,     13, 151645,    198, 151644,    872,\n",
      "            198,  24669,    220,     16,     25,    220, 151652, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151653,  44063, 105995,  69041,  77559, 108215,     24,     15,\n",
      "          26381,  49720,    279,   6249,    220,     24,     15,  12348,    311,\n",
      "            279,   2115,     13,  58230,    228, 105995,  46670,  17714,  65278,\n",
      "          61443, 105995,  11999,    279,   6249,    311,    264,   3265,   5239,\n",
      "             13,  58230,    228, 107620, 110697,  26939, 102690,  57452, 107372,\n",
      "          11999,    279,   6249,    311,    264,  34211,    594,  46697,   1651,\n",
      "             13,    220,  58230,    228, 105995,  46670,  17714,  80942,  63836,\n",
      "         105995,  11999,    279,   6249,    311,    264,   6884,  34381,  18342,\n",
      "             13, 151645,    198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.2809, -1.3385, -1.3964,  ..., -1.2787, -1.2597, -1.2751],\n",
      "        [-1.5183, -1.4832, -1.5793,  ..., -1.3038, -1.3043, -1.3074],\n",
      "        [-1.3133, -1.3185, -1.2903,  ..., -1.3487, -1.3452, -1.3598],\n",
      "        ...,\n",
      "        [-1.6626, -1.6774, -1.6764,  ..., -1.3340, -1.3299, -1.3187],\n",
      "        [-1.6502, -1.6630, -1.6645,  ..., -1.3067, -1.2753, -1.2526],\n",
      "        [-1.6754, -1.6748, -1.6749,  ..., -1.3378, -1.3236, -1.3238]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 42, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3108, 1176)\n",
      "Min: -1.8282335996627808, Max: 2.168954372406006, Mean: -0.7451295256614685\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 860, 3584)\n",
      "Min: -181.0, Max: 128.0, Mean: -0.130859375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.23583469400182366 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 711, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 113.62726593017578\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.2667, -1.2667, -1.2667,  ..., -0.8217, -0.8335, -0.8606],\n",
      "        [-1.3121, -1.3076, -1.3473,  ..., -1.1973, -1.1864, -1.1730],\n",
      "        [-1.1496, -1.1381, -1.1240,  ..., -0.6462, -0.6098, -0.6079],\n",
      "        ...,\n",
      "        [ 1.0859, -0.1256, -0.2868,  ...,  0.6197,  0.4291,  0.0579],\n",
      "        [-1.1702, -1.0602, -0.5905,  ...,  0.6149, -0.1937, -1.1534],\n",
      "        [-1.6150, -0.8690,  0.2011,  ...,  0.5735,  0.3593,  0.0601]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 50, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3700, 1176)\n",
      "Min: -1.8720948696136475, Max: 2.249417543411255, Mean: -0.012816129252314568\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 992, 3584)\n",
      "Min: -186.0, Max: 135.0, Mean: -0.1396484375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.2506421610014513 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 711, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 113.62726593017578\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.2667, -1.2667, -1.2667,  ..., -0.8217, -0.8335, -0.8606],\n",
      "        [-1.3121, -1.3076, -1.3473,  ..., -1.1973, -1.1864, -1.1730],\n",
      "        [-1.1496, -1.1381, -1.1240,  ..., -0.6462, -0.6098, -0.6079],\n",
      "        ...,\n",
      "        [ 1.0859, -0.1256, -0.2868,  ...,  0.6197,  0.4291,  0.0579],\n",
      "        [-1.1702, -1.0602, -0.5905,  ...,  0.6149, -0.1937, -1.1534],\n",
      "        [-1.6150, -0.8690,  0.2011,  ...,  0.5735,  0.3593,  0.0601]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 50, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3700, 1176)\n",
      "Min: -1.8720948696136475, Max: 2.249417543411255, Mean: -0.012816129252314568\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 969, 3584)\n",
      "Min: -186.0, Max: 135.0, Mean: -0.1396484375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.24892258399631828 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 819, 1024)\n",
      "Min: 5.0, Max: 245.00001525878906, Mean: 73.38787078857422\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.5443, -1.5443, -1.5443,  ..., -1.2811, -1.2811, -1.2811],\n",
      "        [-1.5304, -1.5153, -1.5399,  ..., -1.2807, -1.2811, -1.2811],\n",
      "        [-1.5879, -1.5879, -1.5879,  ..., -1.2811, -1.2811, -1.2811],\n",
      "        ...,\n",
      "        [-1.5606, -1.5608, -1.5594,  ..., -1.2243, -1.2243, -1.2243],\n",
      "        [-1.5721, -1.5686, -1.5575,  ..., -1.3348, -1.3080, -1.3080],\n",
      "        [-1.5571, -1.5433, -1.5442,  ..., -1.2525, -1.2382, -1.2242]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 58, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (4292, 1176)\n",
      "Min: -1.7186729907989502, Max: 2.005134344100952, Mean: -0.602754533290863\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1132, 3584)\n",
      "Min: -166.0, Max: 126.5, Mean: -0.1259765625\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.2945258499821648 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 711, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 113.62726593017578\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.2667, -1.2667, -1.2667,  ..., -0.8217, -0.8335, -0.8606],\n",
      "        [-1.3121, -1.3076, -1.3473,  ..., -1.1973, -1.1864, -1.1730],\n",
      "        [-1.1496, -1.1381, -1.1240,  ..., -0.6462, -0.6098, -0.6079],\n",
      "        ...,\n",
      "        [ 1.0859, -0.1256, -0.2868,  ...,  0.6197,  0.4291,  0.0579],\n",
      "        [-1.1702, -1.0602, -0.5905,  ...,  0.6149, -0.1937, -1.1534],\n",
      "        [-1.6150, -0.8690,  0.2011,  ...,  0.5735,  0.3593,  0.0601]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 50, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3700, 1176)\n",
      "Min: -1.8720948696136475, Max: 2.249417543411255, Mean: -0.012816129252314568\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 972, 3584)\n",
      "Min: -186.0, Max: 135.0, Mean: -0.140625\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.25253281102050096 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 575, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 63.50874710083008\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  74785,    279,   1376,   4419,    315,    279,\n",
      "           1946,   2168,    320,   3423,     11,   6083,     11,   1379,     11,\n",
      "          10434,     11,   6171,     11,   4004,    701,   1221,  10339,   1246,\n",
      "            279,   1196,    594,   1467,   7600,   1265,  11596,    476,   5602,\n",
      "            279,   2168,     13,  19813,    264,    501,   2168,    429,  20027,\n",
      "            279,   1196,    594,   8502,   1393,  20337,  28137,    448,    279,\n",
      "           4024,   1946,   1380,   8311,     13, 151645,    198, 151644,    872,\n",
      "            198,  24669,    220,     16,     25,    220, 151652, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151653,  44063, 105995,  69041,  64817, 108215,     24,     15,\n",
      "          26381,  49720,    279,   6249,    220,     24,     15,  12348,    311,\n",
      "            279,   1290,     13,  58230,    228, 107620, 106438, 100462, 121751,\n",
      "         107372,  11999,    279,   6249,    311,    264,  11958,    594,  46697,\n",
      "           1651,     13, 151645,    198, 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0'), 'pixel_values': tensor([[-1.2809, -1.3385, -1.3964,  ..., -1.2787, -1.2597, -1.2751],\n",
      "        [-1.5183, -1.4832, -1.5793,  ..., -1.3038, -1.3043, -1.3074],\n",
      "        [-1.3133, -1.3185, -1.2903,  ..., -1.3487, -1.3452, -1.3598],\n",
      "        ...,\n",
      "        [-1.6626, -1.6774, -1.6764,  ..., -1.3340, -1.3299, -1.3187],\n",
      "        [-1.6502, -1.6630, -1.6645,  ..., -1.3067, -1.2753, -1.2526],\n",
      "        [-1.6754, -1.6748, -1.6749,  ..., -1.3378, -1.3236, -1.3238]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 42, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3108, 1176)\n",
      "Min: -1.8282335996627808, Max: 2.168954372406006, Mean: -0.7451295256614685\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 825, 3584)\n",
      "Min: -181.0, Max: 128.0, Mean: -0.130859375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.23513541498687118 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 1024, 812)\n",
      "Min: 0.0, Max: 255.0, Mean: 159.07200622558594\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-0.1280, -0.1572, -0.1718,  ...,  0.0113,  0.0130,  0.0130],\n",
      "        [-0.1280, -0.1280, -0.0842,  ...,  0.0413,  0.0413,  0.0413],\n",
      "        [-0.1426, -0.1572, -0.1718,  ...,  0.0516,  0.0560,  0.0516],\n",
      "        ...,\n",
      "        [ 1.5946,  1.5946,  1.5946,  ...,  1.8331,  1.8331,  1.8188],\n",
      "        [ 1.6100,  1.6100,  1.6100,  ...,  1.1334,  1.1334,  1.1334],\n",
      "        [ 1.6100,  1.6100,  1.6092,  ...,  1.1050,  1.1050,  1.1050]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 74, 58]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (4292, 1176)\n",
      "Min: -1.7411859035491943, Max: 2.1950085163116455, Mean: 0.6495240926742554\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1150, 3584)\n",
      "Min: -176.0, Max: 128.0, Mean: -0.1416015625\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.291092328960076 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 1024, 812)\n",
      "Min: 0.0, Max: 255.0, Mean: 159.07200622558594\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-0.1280, -0.1572, -0.1718,  ...,  0.0113,  0.0130,  0.0130],\n",
      "        [-0.1280, -0.1280, -0.0842,  ...,  0.0413,  0.0413,  0.0413],\n",
      "        [-0.1426, -0.1572, -0.1718,  ...,  0.0516,  0.0560,  0.0516],\n",
      "        ...,\n",
      "        [ 1.5946,  1.5946,  1.5946,  ...,  1.8331,  1.8331,  1.8188],\n",
      "        [ 1.6100,  1.6100,  1.6100,  ...,  1.1334,  1.1334,  1.1334],\n",
      "        [ 1.6100,  1.6100,  1.6092,  ...,  1.1050,  1.1050,  1.1050]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 74, 58]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (4292, 1176)\n",
      "Min: -1.7411859035491943, Max: 2.1950085163116455, Mean: 0.6495240926742554\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1136, 3584)\n",
      "Min: -176.0, Max: 131.0, Mean: -0.1416015625\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.29379134089685977 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 1024, 812)\n",
      "Min: 0.0, Max: 255.0, Mean: 159.07200622558594\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-0.1280, -0.1572, -0.1718,  ...,  0.0113,  0.0130,  0.0130],\n",
      "        [-0.1280, -0.1280, -0.0842,  ...,  0.0413,  0.0413,  0.0413],\n",
      "        [-0.1426, -0.1572, -0.1718,  ...,  0.0516,  0.0560,  0.0516],\n",
      "        ...,\n",
      "        [ 1.5946,  1.5946,  1.5946,  ...,  1.8331,  1.8331,  1.8188],\n",
      "        [ 1.6100,  1.6100,  1.6100,  ...,  1.1334,  1.1334,  1.1334],\n",
      "        [ 1.6100,  1.6100,  1.6092,  ...,  1.1050,  1.1050,  1.1050]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 74, 58]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (4292, 1176)\n",
      "Min: -1.7411859035491943, Max: 2.1950085163116455, Mean: 0.6495240926742554\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1104, 3584)\n",
      "Min: -176.0, Max: 124.0, Mean: -0.142578125\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.2909910239977762 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 711, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 113.62726593017578\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.2667, -1.2667, -1.2667,  ..., -0.8217, -0.8335, -0.8606],\n",
      "        [-1.3121, -1.3076, -1.3473,  ..., -1.1973, -1.1864, -1.1730],\n",
      "        [-1.1496, -1.1381, -1.1240,  ..., -0.6462, -0.6098, -0.6079],\n",
      "        ...,\n",
      "        [ 1.0859, -0.1256, -0.2868,  ...,  0.6197,  0.4291,  0.0579],\n",
      "        [-1.1702, -1.0602, -0.5905,  ...,  0.6149, -0.1937, -1.1534],\n",
      "        [-1.6150, -0.8690,  0.2011,  ...,  0.5735,  0.3593,  0.0601]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 50, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3700, 1176)\n",
      "Min: -1.8720948696136475, Max: 2.249417543411255, Mean: -0.012816129252314568\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 952, 3584)\n",
      "Min: -186.0, Max: 135.0, Mean: -0.140625\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.2506160920020193 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 1024, 812)\n",
      "Min: 0.0, Max: 255.0, Mean: 159.07200622558594\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-0.1280, -0.1572, -0.1718,  ...,  0.0113,  0.0130,  0.0130],\n",
      "        [-0.1280, -0.1280, -0.0842,  ...,  0.0413,  0.0413,  0.0413],\n",
      "        [-0.1426, -0.1572, -0.1718,  ...,  0.0516,  0.0560,  0.0516],\n",
      "        ...,\n",
      "        [ 1.5946,  1.5946,  1.5946,  ...,  1.8331,  1.8331,  1.8188],\n",
      "        [ 1.6100,  1.6100,  1.6100,  ...,  1.1334,  1.1334,  1.1334],\n",
      "        [ 1.6100,  1.6100,  1.6092,  ...,  1.1050,  1.1050,  1.1050]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 74, 58]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (4292, 1176)\n",
      "Min: -1.7411859035491943, Max: 2.1950085163116455, Mean: 0.6495240926742554\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1118, 3584)\n",
      "Min: -176.0, Max: 126.5, Mean: -0.1416015625\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.29039270197972655 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 819, 1024)\n",
      "Min: 5.0, Max: 245.00001525878906, Mean: 73.38787078857422\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.5443, -1.5443, -1.5443,  ..., -1.2811, -1.2811, -1.2811],\n",
      "        [-1.5304, -1.5153, -1.5399,  ..., -1.2807, -1.2811, -1.2811],\n",
      "        [-1.5879, -1.5879, -1.5879,  ..., -1.2811, -1.2811, -1.2811],\n",
      "        ...,\n",
      "        [-1.5606, -1.5608, -1.5594,  ..., -1.2243, -1.2243, -1.2243],\n",
      "        [-1.5721, -1.5686, -1.5575,  ..., -1.3348, -1.3080, -1.3080],\n",
      "        [-1.5571, -1.5433, -1.5442,  ..., -1.2525, -1.2382, -1.2242]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 58, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (4292, 1176)\n",
      "Min: -1.7186729907989502, Max: 2.005134344100952, Mean: -0.602754533290863\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1131, 3584)\n",
      "Min: -166.0, Max: 127.5, Mean: -0.1259765625\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.2878430059645325 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 1024, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 169.12490844726562\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[0.1639, 0.1638, 0.1783,  ..., 0.4110, 0.4110, 0.4110],\n",
      "        [0.1639, 0.1639, 0.1639,  ..., 0.4090, 0.4319, 0.4405],\n",
      "        [0.1769, 0.1768, 0.1768,  ..., 0.4213, 0.4213, 0.4213],\n",
      "        ...,\n",
      "        [1.3755, 1.3754, 1.3810,  ..., 1.6029, 1.6011, 1.5879],\n",
      "        [1.3752, 1.3795, 1.3913,  ..., 1.7336, 1.7336, 1.7336],\n",
      "        [1.3904, 1.3903, 1.3903,  ..., 1.7336, 1.7336, 1.7336]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 74, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (5476, 1176)\n",
      "Min: -1.7604045867919922, Max: 2.2139892578125, Mean: 0.7960162162780762\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1390, 3584)\n",
      "Min: -190.0, Max: 122.5, Mean: -0.162109375\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.3776645170291886 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 819, 1024)\n",
      "Min: 5.0, Max: 245.00001525878906, Mean: 73.38787078857422\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.5443, -1.5443, -1.5443,  ..., -1.2811, -1.2811, -1.2811],\n",
      "        [-1.5304, -1.5153, -1.5399,  ..., -1.2807, -1.2811, -1.2811],\n",
      "        [-1.5879, -1.5879, -1.5879,  ..., -1.2811, -1.2811, -1.2811],\n",
      "        ...,\n",
      "        [-1.5606, -1.5608, -1.5594,  ..., -1.2243, -1.2243, -1.2243],\n",
      "        [-1.5721, -1.5686, -1.5575,  ..., -1.3348, -1.3080, -1.3080],\n",
      "        [-1.5571, -1.5433, -1.5442,  ..., -1.2525, -1.2382, -1.2242]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 58, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (4292, 1176)\n",
      "Min: -1.7186729907989502, Max: 2.005134344100952, Mean: -0.602754533290863\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1149, 3584)\n",
      "Min: -166.0, Max: 127.0, Mean: -0.1259765625\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.2933834990253672 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 512, 896)\n",
      "Min: 0.0, Max: 255.0, Mean: 127.4706802368164\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  74785,    279,   1376,   4419,    315,    279,\n",
      "           1946,   2168,    320,   3423,     11,   6083,     11,   1379,     11,\n",
      "          10434,     11,   6171,     11,   4004,    701,   1221,  10339,   1246,\n",
      "            279,   1196,    594,   1467,   7600,   1265,  11596,    476,   5602,\n",
      "            279,   2168,     13,  19813,    264,    501,   2168,    429,  20027,\n",
      "            279,   1196,    594,   8502,   1393,  20337,  28137,    448,    279,\n",
      "           4024,   1946,   1380,   8311,     13, 151645,    198, 151644,    872,\n",
      "            198,  24669,    220,     16,     25,    220, 151652, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653,  44063,\n",
      "         105995,  69041,  77559, 108215,     19,     20,  26381,  49720,    279,\n",
      "           6249,    220,     19,     20,  12348,    311,    279,   2115,     13,\n",
      "          58230,    228, 107620, 110697,  26939, 102690,  57452, 107372,  11999,\n",
      "            279,   6249,    311,    264,  34211,    594,  46697,   1651,     13,\n",
      "         151645,    198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[1.0544, 1.0398, 0.9960,  ..., 1.4028, 1.4420, 1.4439],\n",
      "        [1.0690, 1.0690, 1.0690,  ..., 1.4382, 1.4361, 1.4336],\n",
      "        [1.0948, 1.1056, 1.1284,  ..., 1.4509, 1.4499, 1.4431],\n",
      "        ...,\n",
      "        [0.5789, 0.5943, 0.6037,  ..., 0.7682, 0.7563, 0.7712],\n",
      "        [0.3476, 0.3538, 0.4004,  ..., 0.5106, 0.5245, 0.4960],\n",
      "        [0.4727, 0.4748, 0.4720,  ..., 0.6245, 0.6248, 0.6248]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 36, 64]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (2304, 1176)\n",
      "Min: -1.8204282522201538, Max: 2.206862211227417, Mean: 0.18789313733577728\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 625, 3584)\n",
      "Min: -189.0, Max: 126.5, Mean: -0.1328125\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.17909824196249247 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 819, 1024)\n",
      "Min: 5.0, Max: 245.00001525878906, Mean: 73.38787078857422\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.5443, -1.5443, -1.5443,  ..., -1.2811, -1.2811, -1.2811],\n",
      "        [-1.5304, -1.5153, -1.5399,  ..., -1.2807, -1.2811, -1.2811],\n",
      "        [-1.5879, -1.5879, -1.5879,  ..., -1.2811, -1.2811, -1.2811],\n",
      "        ...,\n",
      "        [-1.5606, -1.5608, -1.5594,  ..., -1.2243, -1.2243, -1.2243],\n",
      "        [-1.5721, -1.5686, -1.5575,  ..., -1.3348, -1.3080, -1.3080],\n",
      "        [-1.5571, -1.5433, -1.5442,  ..., -1.2525, -1.2382, -1.2242]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 58, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (4292, 1176)\n",
      "Min: -1.7186729907989502, Max: 2.005134344100952, Mean: -0.602754533290863\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 1136, 3584)\n",
      "Min: -166.0, Max: 132.0, Mean: -0.125\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.290938989026472 seconds\n",
      "_get_qwen_prompt_embeds, image\n",
      "Shape: (3, 683, 1024)\n",
      "Min: 0.0, Max: 255.0, Mean: 63.53046417236328\n",
      "Device: cpu, Dtype: torch.float32, Requires Grad: False\n",
      "{'input_ids': tensor([[151644,   8948,    198,  74785,    279,   1376,   4419,    315,    279,\n",
      "           1946,   2168,    320,   3423,     11,   6083,     11,   1379,     11,\n",
      "          10434,     11,   6171,     11,   4004,    701,   1221,  10339,   1246,\n",
      "            279,   1196,    594,   1467,   7600,   1265,  11596,    476,   5602,\n",
      "            279,   2168,     13,  19813,    264,    501,   2168,    429,  20027,\n",
      "            279,   1196,    594,   8502,   1393,  20337,  28137,    448,    279,\n",
      "           4024,   1946,   1380,   8311,     13, 151645,    198, 151644,    872,\n",
      "            198,  24669,    220,     16,     25,    220, 151652, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "         151655, 151655, 151655, 151655, 151653,  44063, 105995,  69041,  64817,\n",
      "         108215,     24,     15,  26381,  49720,    279,   6249,    220,     24,\n",
      "             15,  12348,    311,    279,   1290,     13,  58230,    228, 107620,\n",
      "         106438, 100462, 121751, 107372,  11999,    279,   6249,    311,    264,\n",
      "          11958,    594,  46697,   1651,     13, 151645,    198, 151644,  77091,\n",
      "            198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.7777, -1.7632, -1.7631,  ..., -0.5286, -0.6148, -0.7006],\n",
      "        [-1.7381, -1.7182, -1.7566,  ..., -0.9265, -0.9171, -0.9117],\n",
      "        [-1.7631, -1.7485, -1.7555,  ..., -0.4396, -0.4960, -0.5632],\n",
      "        ...,\n",
      "        [-1.6908, -1.7087, -1.7196,  ..., -0.5421, -0.5706, -0.5549],\n",
      "        [-1.7173, -1.7147, -1.6992,  ..., -0.7265, -0.7266, -0.7266],\n",
      "        [-1.7319, -1.7304, -1.7315,  ..., -0.6268, -0.6268, -0.5985]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 48, 74]], device='cuda:0')}\n",
      "_get_qwen_prompt_embeds, model_inputs.pixel_values\n",
      "Shape: (3552, 1176)\n",
      "Min: -1.8659758567810059, Max: 2.1775243282318115, Mean: -0.7494064569473267\n",
      "Device: cuda:0, Dtype: torch.float32, Requires Grad: False\n",
      "encode_prompt, prompt_embeds\n",
      "Shape: (1, 936, 3584)\n",
      "Min: -188.0, Max: 128.0, Mean: -0.11572265625\n",
      "Device: cuda:0, Dtype: torch.bfloat16, Requires Grad: False\n",
      "Time taken by QwenImageEditPlusPipeline.encode_prompt: 0.2587369130924344 seconds\n",
      "torch.Size([31844, 3584])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.v2 as T\n",
    "import torch\n",
    "\n",
    "_transforms = T.Compose([\n",
    "    T.ToImage(),\n",
    "    T.RGB(),\n",
    "    T.ToDtype(torch.float32, scale=True), # [0,1]\n",
    "])\n",
    "\n",
    "\n",
    "iterations = 32\n",
    "quant_type = None # \"int8wo\" \"int4wo\" \"fp8row\"\n",
    "if quant_type:\n",
    "    simple_quantize_model(text_encoder, quant_type)\n",
    "\n",
    "all_embeds = []\n",
    "for i in range(iterations):\n",
    "    prompt_embeds, prompt_embeds_mask = foundation.pipe.encode_prompt(\n",
    "        inps[i][\"prompt\"],\n",
    "        _transforms(inps[i][\"image\"][0]).mul(255),\n",
    "        device=\"cuda\",\n",
    "        # dtype=foundation.dtype,\n",
    "        max_sequence_length = foundation.config.train_max_sequence_length,\n",
    "    )\n",
    "    all_embeds.append(prompt_embeds.squeeze(0))\n",
    "stacked_embd = torch.cat(all_embeds, dim=0)\n",
    "print(f\"{stacked_embd.shape}\")\n",
    "torch.save(stacked_embd, f\"{quant_type or 'base'}_stacked_embd_{iterations}.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37beb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Image([[[0.0039, 0.0078, 0.0078,  ..., 0.0118, 0.0118, 0.0118],\n",
       "         [0.0039, 0.0078, 0.0078,  ..., 0.0118, 0.0118, 0.0118],\n",
       "         [0.0039, 0.0078, 0.0078,  ..., 0.0118, 0.0118, 0.0157],\n",
       "         ...,\n",
       "         [0.0588, 0.0588, 0.0588,  ..., 0.0275, 0.0235, 0.0235],\n",
       "         [0.0549, 0.0549, 0.0549,  ..., 0.0275, 0.0235, 0.0235],\n",
       "         [0.0510, 0.0510, 0.0510,  ..., 0.0275, 0.0235, 0.0235]],\n",
       " \n",
       "        [[0.1647, 0.1686, 0.1686,  ..., 0.1490, 0.1490, 0.1490],\n",
       "         [0.1647, 0.1686, 0.1686,  ..., 0.1490, 0.1490, 0.1490],\n",
       "         [0.1647, 0.1686, 0.1686,  ..., 0.1490, 0.1529, 0.1569],\n",
       "         ...,\n",
       "         [0.1961, 0.1961, 0.1961,  ..., 0.1294, 0.1294, 0.1294],\n",
       "         [0.1922, 0.1922, 0.1922,  ..., 0.1294, 0.1294, 0.1294],\n",
       "         [0.1882, 0.1882, 0.1882,  ..., 0.1294, 0.1294, 0.1294]],\n",
       " \n",
       "        [[0.2902, 0.2941, 0.2941,  ..., 0.2588, 0.2588, 0.2588],\n",
       "         [0.2902, 0.2941, 0.2941,  ..., 0.2588, 0.2588, 0.2588],\n",
       "         [0.2902, 0.2941, 0.2941,  ..., 0.2588, 0.2549, 0.2588],\n",
       "         ...,\n",
       "         [0.3137, 0.3137, 0.3137,  ..., 0.2353, 0.2353, 0.2431],\n",
       "         [0.3098, 0.3098, 0.3098,  ..., 0.2353, 0.2353, 0.2431],\n",
       "         [0.3059, 0.3059, 0.3059,  ..., 0.2353, 0.2353, 0.2431]]], )]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ec83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
