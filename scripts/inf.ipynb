{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/ubuntu/Qwen-Image-Edit-Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwenimage.datamodels import QwenConfig\n",
    "from qwenimage.finetuner import QwenLoraFinetuner\n",
    "from qwenimage.foundation import QwenImageFoundation, QwenImageRegressionFoundation\n",
    "\n",
    "foundation = QwenImageFoundation(QwenConfig(\n",
    "    vae_image_size=1024 * 1024,\n",
    "    regression_base_pipe_steps=4,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea142808",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuner = QwenLoraFinetuner(foundation, foundation.config)\n",
    "finetuner.load(\"/data/reg-mse-pixel-lpips_005000\", lora_rank=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20cb973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05dc32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07081b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb8982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7dca13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb543d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed778985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwenimage.experiments.experiments_qwen import PipeInputs\n",
    "\n",
    "pipe_inputs = PipeInputs()\n",
    "pipe_inputs[0]\n",
    "from qwenimage.datamodels import QwenInputs\n",
    "\n",
    "idx = 0\n",
    "inps = QwenInputs(**pipe_inputs[idx])\n",
    "inps.num_inference_steps = 4\n",
    "inps.vae_image_override = 1024 * 1024\n",
    "inps.latent_size_override = 1024 * 1024\n",
    "finetuner.enable()\n",
    "foundation.scheduler.config[\"base_shift\"] = 2.5\n",
    "foundation.scheduler.config[\"max_shift\"] = 2.5\n",
    "outs = foundation.base_pipe(inps)\n",
    "outs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwenimage.sources import EditingSource\n",
    "\n",
    "\n",
    "src = EditingSource(\n",
    "    data_dir=\"/data/CrispEdit\",\n",
    "    total_per=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4c5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.image_utils import load_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from qwenimage.datamodels import QwenInputs\n",
    "\n",
    "SEED = 67\n",
    "\n",
    "idx = 15_310\n",
    "text, _, image = src[idx]\n",
    "print(text)\n",
    "\n",
    "inps = QwenInputs(\n",
    "    prompt = text,\n",
    "    image = [image],\n",
    "\n",
    "    # prompt=\"Turn the man into a goblin\",\n",
    "    # image=[load_image(\"/home/ubuntu/Qwen-Image-Edit-Angles/scripts/assets/media_images_sample_images_34141_02388e50bbd59c3efb75.png\")],\n",
    "    \n",
    "    # prompt=\"Turn the background into a deep forest\",\n",
    "    # image=[load_image(\"/home/ubuntu/Qwen-Image-Edit-Angles/scripts/assets/media_images_sample_images_34141_02388e50bbd59c3efb75.png\")],\n",
    "    \n",
    "    # prompt=\"Add a large hot air balloon to the center of the scene\",\n",
    "    # image=[load_image(\"/home/ubuntu/Qwen-Image-Edit-Angles/scripts/assets/wand-3270.png\")],\n",
    "    \n",
    "    # prompt=\"Remove the little girl\",\n",
    "    # image=[load_image(\"/home/ubuntu/Qwen-Image-Edit-Angles/scripts/assets/test_images_v1/test_image_1.jpg\")],\n",
    "    \n",
    "    # prompt=\"Turn the corn into two peaches, one on each hand\",\n",
    "    # image=[load_image(\"/home/ubuntu/Qwen-Image-Edit-Angles/scripts/assets/test_images_v1/test_image_5.jpg\")],\n",
    "    \n",
    "    # prompt=\"Colorize the sketch to a painting of a forest\",\n",
    "    # image=[load_image(\"/home/ubuntu/Qwen-Image-Edit-Angles/scripts/assets/hK1XxQ0li9QS9AlhZitJI.jpeg\")],\n",
    "    \n",
    "    # prompt=\"Remove the furniture and show an completely empty room interior\",\n",
    "    # image=[load_image(\"/home/ubuntu/Qwen-Image-Edit-Angles/scripts/assets/471419729_122147939600372575_2367375612828096747_n.jpg\")],\n",
    "    num_inference_steps = 2,\n",
    "    vae_image_override = 1024 * 1024,\n",
    "    latent_size_override = 1024 * 1024,\n",
    ")\n",
    "\n",
    "finetuner.enable()\n",
    "foundation.scheduler.config[\"base_shift\"] = 2.0\n",
    "foundation.scheduler.config[\"max_shift\"] = 2.0\n",
    "inps.generator = torch.Generator().manual_seed(SEED)\n",
    "outs_distill = foundation.base_pipe(inps)\n",
    "\n",
    "finetuner.disable()\n",
    "foundation.scheduler.config[\"base_shift\"] = 0.5\n",
    "foundation.scheduler.config[\"max_shift\"] = 0.9\n",
    "inps.generator = torch.Generator().manual_seed(SEED)\n",
    "outs_base_2step = foundation.base_pipe(inps)\n",
    "\n",
    "inps.num_inference_steps = 50\n",
    "inps.generator = torch.Generator().manual_seed(SEED)\n",
    "outs_base_50step = foundation.base_pipe(inps)\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# Plot input image\n",
    "axes[0].imshow(inps.image[0])\n",
    "axes[0].set_title(\"Input Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Plot base 50 step output\n",
    "axes[1].imshow(outs_base_50step[0])\n",
    "axes[1].set_title(\"Base 50 Steps\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Plot base 2 step output\n",
    "axes[2].imshow(outs_base_2step[0])\n",
    "axes[2].set_title(\"Base 2 Steps\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "# # Plot distilled output\n",
    "axes[3].imshow(outs_distill[0])\n",
    "axes[3].set_title(\"Distilled\")\n",
    "axes[3].axis('off')\n",
    "\n",
    "# Set the prompt as the main title\n",
    "fig.suptitle(inps.prompt, fontsize=14, wrap=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6bdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e72b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03c7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
