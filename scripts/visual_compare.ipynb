{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5649df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Qwen-Image-Edit-Angles\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/Qwen-Image-Edit-Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "Skipping import of cpp extensions due to incompatible torch version 2.9.1+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info\n",
      "TMA benchmarks will be running without grid constant TMA descriptor.\n",
      "2025-11-15 00:25:52.163576: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-15 00:25:52.177532: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763166352.194580 1401631 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763166352.200097 1401631 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1763166352.213216 1401631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763166352.213231 1401631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763166352.213234 1401631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763166352.213235 1401631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-15 00:25:52.217652: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 80659.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from qwenimage.experiments.experiments_qwen import PipeInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwenimage.experiment import ExperimentConfig\n",
    "from qwenimage.experiments.experiments_qwen import ExperimentRegistry\n",
    "\n",
    "\n",
    "experiment_names = [\n",
    "    \"qwen_base\",\n",
    "    \"qwen_lightning_fa3_aot_int8_fuse_4step_fbcache_055_downsize512\",\n",
    "    \"qwen_lightning_fa3_aot_int8_fuse_1step_fbcache_055_downsize512\",\n",
    "]\n",
    "\n",
    "report_dir = ExperimentConfig().report_dir\n",
    "\n",
    "experiment_outputs = {}\n",
    "num_outputs = {}\n",
    "for name in experiment_names:\n",
    "    output_dir = report_dir / f\"{name}_outputs\"\n",
    "    all_output_paths = sorted(list(output_dir.glob(\"*.jpg\")))\n",
    "    experiment_outputs[name] = all_output_paths\n",
    "    num_outputs[name] = len(all_output_paths)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29077eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('reports/qwen_base_outputs/000.jpg')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_outputs[\"qwen_base\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591fdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce90b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601aa246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa95f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ded7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d431a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ecb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e36dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 input combinations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved comparison grid 1/32 to reports/comparison_grid_4/comparison_000.jpg\n",
      "Saved comparison grid 2/32 to reports/comparison_grid_4/comparison_001.jpg\n",
      "Saved comparison grid 3/32 to reports/comparison_grid_4/comparison_002.jpg\n",
      "Saved comparison grid 4/32 to reports/comparison_grid_4/comparison_003.jpg\n",
      "Saved comparison grid 5/32 to reports/comparison_grid_4/comparison_004.jpg\n",
      "Saved comparison grid 6/32 to reports/comparison_grid_4/comparison_005.jpg\n",
      "Saved comparison grid 7/32 to reports/comparison_grid_4/comparison_006.jpg\n",
      "Saved comparison grid 8/32 to reports/comparison_grid_4/comparison_007.jpg\n",
      "Saved comparison grid 9/32 to reports/comparison_grid_4/comparison_008.jpg\n",
      "Saved comparison grid 10/32 to reports/comparison_grid_4/comparison_009.jpg\n",
      "Saved comparison grid 11/32 to reports/comparison_grid_4/comparison_010.jpg\n",
      "Saved comparison grid 12/32 to reports/comparison_grid_4/comparison_011.jpg\n",
      "Saved comparison grid 13/32 to reports/comparison_grid_4/comparison_012.jpg\n",
      "Saved comparison grid 14/32 to reports/comparison_grid_4/comparison_013.jpg\n",
      "Saved comparison grid 15/32 to reports/comparison_grid_4/comparison_014.jpg\n",
      "Saved comparison grid 16/32 to reports/comparison_grid_4/comparison_015.jpg\n",
      "Saved comparison grid 17/32 to reports/comparison_grid_4/comparison_016.jpg\n",
      "Saved comparison grid 18/32 to reports/comparison_grid_4/comparison_017.jpg\n",
      "Saved comparison grid 19/32 to reports/comparison_grid_4/comparison_018.jpg\n",
      "Saved comparison grid 20/32 to reports/comparison_grid_4/comparison_019.jpg\n",
      "Saved comparison grid 21/32 to reports/comparison_grid_4/comparison_020.jpg\n",
      "Saved comparison grid 22/32 to reports/comparison_grid_4/comparison_021.jpg\n",
      "Saved comparison grid 23/32 to reports/comparison_grid_4/comparison_022.jpg\n",
      "Saved comparison grid 24/32 to reports/comparison_grid_4/comparison_023.jpg\n",
      "Saved comparison grid 25/32 to reports/comparison_grid_4/comparison_024.jpg\n",
      "Saved comparison grid 26/32 to reports/comparison_grid_4/comparison_025.jpg\n",
      "Saved comparison grid 27/32 to reports/comparison_grid_4/comparison_026.jpg\n",
      "Saved comparison grid 28/32 to reports/comparison_grid_4/comparison_027.jpg\n",
      "Saved comparison grid 29/32 to reports/comparison_grid_4/comparison_028.jpg\n",
      "Saved comparison grid 30/32 to reports/comparison_grid_4/comparison_029.jpg\n",
      "Saved comparison grid 31/32 to reports/comparison_grid_4/comparison_030.jpg\n",
      "Saved comparison grid 32/32 to reports/comparison_grid_4/comparison_031.jpg\n",
      "\n",
      "All comparison grids saved to reports/comparison_grid_4\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Configure Chinese font\n",
    "font_path = Path(\"scripts/assets/STSong.ttf\")\n",
    "chinese_font = fm.FontProperties(fname=str(font_path))\n",
    "\n",
    "comparison_dir = report_dir / \"comparison_grid_4\"\n",
    "comparison_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Create PipeInputs instance to access original images and prompts\n",
    "pipe_inputs = PipeInputs(seed=42)\n",
    "\n",
    "comparable_outputs = min(num_outputs.values())\n",
    "num_experiments = len(experiment_names)\n",
    "\n",
    "# For each output index, create a comparison grid\n",
    "for idx in range(comparable_outputs):\n",
    "    # Get the original image and prompt for this index\n",
    "    inputs = pipe_inputs[idx]\n",
    "    original_image = inputs[\"image\"][0]\n",
    "    prompt = inputs[\"prompt\"]\n",
    "    \n",
    "    # Calculate grid size: +1 for original image\n",
    "    total_plots = num_experiments + 1\n",
    "    cols = int(math.ceil(math.sqrt(total_plots)))\n",
    "    if total_plots == 3:\n",
    "        cols = 3 # hard override for formatting\n",
    "    rows = int(math.ceil(total_plots / cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 6 * rows))\n",
    "    \n",
    "    # Flatten axes array for easier indexing\n",
    "    if total_plots == 1:\n",
    "        axes = np.array([axes])\n",
    "    else:\n",
    "        axes = axes.flatten() if isinstance(axes, np.ndarray) else np.array([axes])\n",
    "    \n",
    "    # Plot original image in the first subplot\n",
    "    ax = axes[0]\n",
    "    ax.imshow(original_image)\n",
    "    ax.set_title(\"Original Image\", fontsize=14, fontweight='bold', color='blue')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Plot each experiment's output for this index\n",
    "    for exp_idx, exp_name in enumerate(experiment_names):\n",
    "        ax = axes[exp_idx + 1]  # +1 because first subplot is original image\n",
    "        \n",
    "        # Check if this experiment has an output at this index\n",
    "        if idx < num_outputs[exp_name]:\n",
    "            img_path = experiment_outputs[exp_name][idx]\n",
    "            img = Image.open(img_path)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(exp_name, fontsize=14, fontweight='bold')\n",
    "        else:\n",
    "            # No output for this experiment at this index\n",
    "            ax.text(0.5, 0.5, 'N/A', ha='center', va='center', fontsize=20)\n",
    "            ax.set_title(exp_name, fontsize=14, fontweight='bold', color='gray')\n",
    "        \n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for plot_idx in range(total_plots, len(axes)):\n",
    "        axes[plot_idx].axis('off')\n",
    "    \n",
    "    # Wrap prompt text for better display\n",
    "    wrapped_prompt = '\\n'.join(textwrap.wrap(prompt, width=100))\n",
    "    \n",
    "    # Add a main title with the prompt\n",
    "    fig.suptitle(\n",
    "        f'Output Comparison - Index {idx:03d}\\nPrompt: {wrapped_prompt}',\n",
    "        fontsize=16,\n",
    "        fontweight='bold',\n",
    "        y=0.99,\n",
    "        fontproperties=chinese_font\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    output_path = comparison_dir / f\"comparison_{idx:03d}.jpg\"\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"Saved comparison grid {idx + 1}/{comparable_outputs} to {output_path}\")\n",
    "\n",
    "print(f\"\\nAll comparison grids saved to {comparison_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c9749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244dfe0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
