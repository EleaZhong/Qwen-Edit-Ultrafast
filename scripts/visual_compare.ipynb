{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5649df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/ubuntu/Qwen-Image-Edit-Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwenimage.experiment import ExperimentConfig\n",
    "from qwenimage.experiments.experiments_qwen import ExperimentRegistry\n",
    "\n",
    "\n",
    "# experiment_names = ExperimentRegistry.keys()\n",
    "# experiment_names = [\n",
    "#     \"qwen_base\",\n",
    "#     # \"qwen_fa3\",\n",
    "#     # \"qwen_aot\",\n",
    "#     # \"qwen_fa3_aot\",\n",
    "#     # \"qwen_fa3_aot_int8\",\n",
    "#     # \"qwen_fa3_aot_fp8\",\n",
    "#     # \"qwen_fuse\",\n",
    "#     \"qwen_base_3step\",\n",
    "#     \"qwen_base_2step\",\n",
    "#     \"qwen_lightning_lora\",\n",
    "#     \"qwen_lightning_lora_3step\",\n",
    "#     \"qwen_lightning_lora_2step\",\n",
    "# ]\n",
    "\n",
    "experiment_names = [\n",
    "    # \"qwen_fa3\",\n",
    "    # \"qwen_aot\",\n",
    "    # \"qwen_fa3_aot\",\n",
    "    \"qwen_fa3_aot_int8\",\n",
    "    \"qwen_fa3_aot_int8_fuse\",\n",
    "    \"qwen_lightning_fa3_aot_int8_fuse\",\n",
    "    # \"qwen_fa3_fuse\",\n",
    "    \"qwen_fa3_aot_fp8\",\n",
    "    \"qwen_fa3_aot_fp8_fuse\",\n",
    "    \"qwen_lightning_fa3_aot_fp8_fuse\",\n",
    "    \"qwen_lightning_fa3_aot_int8_fuse_2step\",\n",
    "    \"qwen_base\",\n",
    "]\n",
    "\n",
    "report_dir = ExperimentConfig().report_dir\n",
    "\n",
    "experiment_outputs = {}\n",
    "num_outputs = {}\n",
    "for name in experiment_names:\n",
    "    output_dir = report_dir / f\"{name}_outputs\"\n",
    "    all_output_paths = sorted(list(output_dir.glob(\"*.jpg\")))\n",
    "    experiment_outputs[name] = all_output_paths\n",
    "    num_outputs[name] = len(all_output_paths)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29077eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_outputs[\"qwen_base\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591fdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce90b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601aa246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa95f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ded7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d431a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ecb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e36dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "comparison_dir = report_dir / \"comparison_grid_2\"\n",
    "comparison_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "comparable_outputs = min(num_outputs.values())\n",
    "num_experiments = len(experiment_names)\n",
    "\n",
    "# For each output index, create a comparison grid\n",
    "for idx in range(comparable_outputs):\n",
    "    cols = int(math.ceil(math.sqrt(num_experiments)))\n",
    "    rows = int(math.ceil(num_experiments / cols ))\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 6 * rows))\n",
    "    \n",
    "    # Flatten axes array for easier indexing\n",
    "    if num_experiments == 1:\n",
    "        axes = np.array([axes])\n",
    "    else:\n",
    "        axes = axes.flatten() if isinstance(axes, np.ndarray) else np.array([axes])\n",
    "    \n",
    "    # Plot each experiment's output for this index\n",
    "    for exp_idx, exp_name in enumerate(experiment_names):\n",
    "        ax = axes[exp_idx]\n",
    "        \n",
    "        # Check if this experiment has an output at this index\n",
    "        if idx < num_outputs[exp_name]:\n",
    "            img_path = experiment_outputs[exp_name][idx]\n",
    "            img = Image.open(img_path)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(exp_name, fontsize=14, fontweight='bold')\n",
    "        else:\n",
    "            # No output for this experiment at this index\n",
    "            ax.text(0.5, 0.5, 'N/A', ha='center', va='center', fontsize=20)\n",
    "            ax.set_title(exp_name, fontsize=14, fontweight='bold', color='gray')\n",
    "        \n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for exp_idx in range(num_experiments, len(axes)):\n",
    "        axes[exp_idx].axis('off')\n",
    "    \n",
    "    # Add a main title for the figure\n",
    "    fig.suptitle(f'Output Comparison - Index {idx:03d}', fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    output_path = comparison_dir / f\"comparison_{idx:03d}.jpg\"\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"Saved comparison grid {idx + 1}/{comparable_outputs} to {output_path}\")\n",
    "\n",
    "print(f\"\\nAll comparison grids saved to {comparison_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c9749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244dfe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lpips\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Initialize LPIPS model\n",
    "loss_fn = lpips.LPIPS(net='alex')  # or 'vgg' or 'squeeze'\n",
    "if torch.cuda.is_available():\n",
    "    loss_fn = loss_fn.cuda()\n",
    "\n",
    "# Transform to convert PIL images to tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "def calculate_lpips_scores(base_paths, compare_paths):\n",
    "    \"\"\"Calculate LPIPS scores between two sets of images.\"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    # Get the minimum number of images available\n",
    "    num_images = min(len(base_paths), len(compare_paths))\n",
    "    \n",
    "    for idx in range(num_images):\n",
    "        # Load images\n",
    "        img1 = Image.open(base_paths[idx]).convert('RGB')\n",
    "        img2 = Image.open(compare_paths[idx]).convert('RGB')\n",
    "        \n",
    "        # Resize if dimensions don't match\n",
    "        if img1.size != img2.size:\n",
    "            img2 = img2.resize(img1.size, Image.LANCZOS)\n",
    "        \n",
    "        # Transform to tensors\n",
    "        img1_tensor = transform(img1).unsqueeze(0)\n",
    "        img2_tensor = transform(img2).unsqueeze(0)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            img1_tensor = img1_tensor.cuda()\n",
    "            img2_tensor = img2_tensor.cuda()\n",
    "        \n",
    "        # Calculate LPIPS\n",
    "        with torch.no_grad():\n",
    "            score = loss_fn(img1_tensor, img2_tensor)\n",
    "        \n",
    "        scores.append(score.item())\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Define experiment sets\n",
    "experiment_sets = {\n",
    "    'qwen_base': {\n",
    "        '4step': 'qwen_base',\n",
    "        '3step': 'qwen_base_3step',\n",
    "        '2step': 'qwen_base_2step'\n",
    "    },\n",
    "    'qwen_lightning_lora': {\n",
    "        '4step': 'qwen_lightning_lora',\n",
    "        '3step': 'qwen_lightning_lora_3step',\n",
    "        '2step': 'qwen_lightning_lora_2step'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Calculate LPIPS scores for each set\n",
    "results = {}\n",
    "\n",
    "for set_name, experiments in experiment_sets.items():\n",
    "    print(f\"\\nProcessing {set_name}...\")\n",
    "    \n",
    "    # Get image paths\n",
    "    base_4step_paths = experiment_outputs[experiments['4step']]\n",
    "    step_3_paths = experiment_outputs[experiments['3step']]\n",
    "    step_2_paths = experiment_outputs[experiments['2step']]\n",
    "    \n",
    "    # Calculate LPIPS scores\n",
    "    print(f\"Calculating LPIPS: 4-step vs 3-step...\")\n",
    "    scores_4vs3 = calculate_lpips_scores(base_4step_paths, step_3_paths)\n",
    "    \n",
    "    print(f\"Calculating LPIPS: 4-step vs 2-step...\")\n",
    "    scores_4vs2 = calculate_lpips_scores(base_4step_paths, step_2_paths)\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results_df = pd.DataFrame({\n",
    "        'comparison': ['4step_vs_3step', '4step_vs_2step'],\n",
    "        'mean_lpips': [\n",
    "            np.mean(scores_4vs3),\n",
    "            np.mean(scores_4vs2)\n",
    "        ],\n",
    "        'std_lpips': [\n",
    "            np.std(scores_4vs3),\n",
    "            np.std(scores_4vs2)\n",
    "        ],\n",
    "        'num_samples': [\n",
    "            len(scores_4vs3),\n",
    "            len(scores_4vs2)\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = report_dir / f\"lpips_scores_{set_name}.csv\"\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"\\nResults for {set_name}:\")\n",
    "    print(results_df)\n",
    "    print(f\"\\nSaved to: {csv_path}\")\n",
    "    \n",
    "    results[set_name] = results_df\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LPIPS Analysis Complete!\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
